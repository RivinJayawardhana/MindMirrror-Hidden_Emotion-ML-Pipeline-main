{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from typing import Any\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Load all four CSV files\n",
        "\n",
        "\n",
        "df1 = pd.read_csv(\"filter_labeled_v2.csv\")\n",
        "df2 = pd.read_csv( \"hidden_emotion_dataset.csv\")\n",
        "df3 = pd.read_csv(\"tweet_labeled3.csv\")\n",
        "df4 = pd.read_csv( \"goemotions_final_with_6class_hidden.csv\")\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"DATASET 1: filter_labeled_v2.csv\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Shape: {df1.shape}\")\n",
        "print(f\"\\nColumns: {list(df1.columns)}\")\n",
        "print(f\"\\nFirst 3 rows:\")\n",
        "display(df1.head(3))\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"DATASET 2: hidden_emotion_dataset.csv\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Shape: {df2.shape}\")\n",
        "print(f\"\\nColumns: {list(df2.columns)}\")\n",
        "print(f\"\\nFirst 3 rows:\")\n",
        "display(df2.head(3))\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"DATASET 3: tweets_labeled.csv\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Shape: {df3.shape}\")\n",
        "print(f\"\\nColumns: {list(df3.columns)}\")\n",
        "print(f\"\\nFirst 3 rows:\")\n",
        "display(df3.head(3))\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"DATASET 4: goemotions_final_with_6class_hidden.csv\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Shape: {df4.shape}\")\n",
        "print(f\"\\nColumns: {list(df4.columns)}\")\n",
        "print(f\"\\nFirst 3 rows:\")\n",
        "display(df4.head(3))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "DATASET 1: filter_labeled_v2.csv\n",
            "============================================================\n",
            "Shape: (1192, 14)\n",
            "\n",
            "Columns: ['message_text', 'diggCount', 'timestamp', 'message_id', 'sender_id', 'conversation_id', 'emojis', 'context', 'primary_emoji', 'emoji_emotion', 'hidden_emotion_label', 'hidden_emotion_flag', 'emoji_text_sentiment_match', 'emotion_label']\n",
            "\n",
            "First 3 rows:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>message_text</th>\n",
              "      <th>diggCount</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>message_id</th>\n",
              "      <th>sender_id</th>\n",
              "      <th>conversation_id</th>\n",
              "      <th>emojis</th>\n",
              "      <th>context</th>\n",
              "      <th>primary_emoji</th>\n",
              "      <th>emoji_emotion</th>\n",
              "      <th>hidden_emotion_label</th>\n",
              "      <th>hidden_emotion_flag</th>\n",
              "      <th>emoji_text_sentiment_match</th>\n",
              "      <th>emotion_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"Woah did you draw that?\"\\nNo, I Printed it. O...</td>\n",
              "      <td>3211</td>\n",
              "      <td>2024-07-11T04:27:18.000Z</td>\n",
              "      <td>.juxxy_rvles</td>\n",
              "      <td>7343405289410872325</td>\n",
              "      <td>7390230050099479303</td>\n",
              "      <td>üëπ</td>\n",
              "      <td>\"Woah did you draw that?\"\\nNo, I Printed it. O...</td>\n",
              "      <td>üëπ</td>\n",
              "      <td>anger</td>\n",
              "      <td>joy</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I CANT WITH THESE COMMENTSüò≠üôè</td>\n",
              "      <td>377</td>\n",
              "      <td>2024-07-13T09:08:15.000Z</td>\n",
              "      <td>teabag_pepsiluvr</td>\n",
              "      <td>7289657206936863749</td>\n",
              "      <td>7391044639077368581</td>\n",
              "      <td>üò≠üôè</td>\n",
              "      <td>I CANT WITH THESE COMMENTS</td>\n",
              "      <td>üò≠</td>\n",
              "      <td>sadness</td>\n",
              "      <td>anger</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\" Oh sorry, were you sleeping? \" No, I'm summo...</td>\n",
              "      <td>61</td>\n",
              "      <td>2024-07-29T05:08:15.000Z</td>\n",
              "      <td>aintdyingtoday</td>\n",
              "      <td>7107200072383661082</td>\n",
              "      <td>7396920095761466129</td>\n",
              "      <td>üíÄ</td>\n",
              "      <td>\" Oh sorry, were you sleeping? \" No, I'm summo...</td>\n",
              "      <td>üíÄ</td>\n",
              "      <td>anger</td>\n",
              "      <td>joy</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        message_text  diggCount  \\\n",
              "0  \"Woah did you draw that?\"\\nNo, I Printed it. O...       3211   \n",
              "1                       I CANT WITH THESE COMMENTSüò≠üôè        377   \n",
              "2  \" Oh sorry, were you sleeping? \" No, I'm summo...         61   \n",
              "\n",
              "                  timestamp        message_id            sender_id  \\\n",
              "0  2024-07-11T04:27:18.000Z      .juxxy_rvles  7343405289410872325   \n",
              "1  2024-07-13T09:08:15.000Z  teabag_pepsiluvr  7289657206936863749   \n",
              "2  2024-07-29T05:08:15.000Z    aintdyingtoday  7107200072383661082   \n",
              "\n",
              "       conversation_id emojis  \\\n",
              "0  7390230050099479303      üëπ   \n",
              "1  7391044639077368581     üò≠üôè   \n",
              "2  7396920095761466129      üíÄ   \n",
              "\n",
              "                                             context primary_emoji  \\\n",
              "0  \"Woah did you draw that?\"\\nNo, I Printed it. O...             üëπ   \n",
              "1                         I CANT WITH THESE COMMENTS             üò≠   \n",
              "2  \" Oh sorry, were you sleeping? \" No, I'm summo...             üíÄ   \n",
              "\n",
              "  emoji_emotion hidden_emotion_label  hidden_emotion_flag  \\\n",
              "0         anger                  joy                 True   \n",
              "1       sadness                anger                 True   \n",
              "2         anger                  joy                False   \n",
              "\n",
              "   emoji_text_sentiment_match emotion_label  \n",
              "0                       False         anger  \n",
              "1                       False       sadness  \n",
              "2                        True         anger  "
            ]
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "DATASET 2: hidden_emotion_dataset.csv\n",
            "============================================================\n",
            "Shape: (2000, 12)\n",
            "\n",
            "Columns: ['message_id', 'conversation_id', 'sender_id', 'timestamp', 'message_text', 'emojis', 'corrected_text', 'context', 'hidden_emotion_label', 'emotion_label', 'emoji_text_sentiment_match', 'hidden_emotion_flag']\n",
            "\n",
            "First 3 rows:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>message_id</th>\n",
              "      <th>conversation_id</th>\n",
              "      <th>sender_id</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>message_text</th>\n",
              "      <th>emojis</th>\n",
              "      <th>corrected_text</th>\n",
              "      <th>context</th>\n",
              "      <th>hidden_emotion_label</th>\n",
              "      <th>emotion_label</th>\n",
              "      <th>emoji_text_sentiment_match</th>\n",
              "      <th>hidden_emotion_flag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2312</td>\n",
              "      <td>@dev_118</td>\n",
              "      <td>2025-09-18T09:45:00Z</td>\n",
              "      <td>Update: argument üò® with partner. worried fr @a...</td>\n",
              "      <td>üò®</td>\n",
              "      <td>Update: argument üò® with partner. Worried for r...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>fear</td>\n",
              "      <td>fear</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2312</td>\n",
              "      <td>@kyle504</td>\n",
              "      <td>2025-09-18T10:00:00Z</td>\n",
              "      <td>Update: argument ü§Ø with partner. shook #smh. I...</td>\n",
              "      <td>ü§Ø</td>\n",
              "      <td>Update: argument ü§Ø with partner. Shook #smh. I...</td>\n",
              "      <td>About that: Worried for real @alex.</td>\n",
              "      <td>surprise</td>\n",
              "      <td>surprise</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2312</td>\n",
              "      <td>@alex.289</td>\n",
              "      <td>2025-09-18T10:12:00Z</td>\n",
              "      <td>About argument with partner. lol down about üòû ...</td>\n",
              "      <td>üòû</td>\n",
              "      <td>About argument with partner. Laughing out loud...</td>\n",
              "      <td>Re: I drafted alternatives in case we get bloc...</td>\n",
              "      <td>sadness</td>\n",
              "      <td>sadness</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   message_id  conversation_id  sender_id             timestamp  \\\n",
              "0           1             2312   @dev_118  2025-09-18T09:45:00Z   \n",
              "1           2             2312   @kyle504  2025-09-18T10:00:00Z   \n",
              "2           3             2312  @alex.289  2025-09-18T10:12:00Z   \n",
              "\n",
              "                                        message_text emojis  \\\n",
              "0  Update: argument üò® with partner. worried fr @a...      üò®   \n",
              "1  Update: argument ü§Ø with partner. shook #smh. I...      ü§Ø   \n",
              "2  About argument with partner. lol down about üòû ...      üòû   \n",
              "\n",
              "                                      corrected_text  \\\n",
              "0  Update: argument üò® with partner. Worried for r...   \n",
              "1  Update: argument ü§Ø with partner. Shook #smh. I...   \n",
              "2  About argument with partner. Laughing out loud...   \n",
              "\n",
              "                                             context hidden_emotion_label  \\\n",
              "0                                                NaN                 fear   \n",
              "1                About that: Worried for real @alex.             surprise   \n",
              "2  Re: I drafted alternatives in case we get bloc...              sadness   \n",
              "\n",
              "  emotion_label  emoji_text_sentiment_match  hidden_emotion_flag  \n",
              "0          fear                        True                False  \n",
              "1      surprise                        True                False  \n",
              "2       sadness                        True                False  "
            ]
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "DATASET 3: tweets_labeled.csv\n",
            "============================================================\n",
            "Shape: (3563, 10)\n",
            "\n",
            "Columns: ['Unnamed: 0.1', 'Unnamed: 0', 'tweets', 'class', 'primary_emoji', 'emoji_emotion', 'emotion_label', 'hidden_emotion_label', 'hidden_emotion_flag', 'emoji_text_sentiment_match']\n",
            "\n",
            "First 3 rows:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>tweets</th>\n",
              "      <th>class</th>\n",
              "      <th>primary_emoji</th>\n",
              "      <th>emoji_emotion</th>\n",
              "      <th>emotion_label</th>\n",
              "      <th>hidden_emotion_label</th>\n",
              "      <th>hidden_emotion_flag</th>\n",
              "      <th>emoji_text_sentiment_match</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>That shitty feeling we all love so much üòä #sar...</td>\n",
              "      <td>figurative</td>\n",
              "      <td>üòä</td>\n",
              "      <td>joy</td>\n",
              "      <td>joy</td>\n",
              "      <td>anger</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>@HOT97 it's pretty obvious @MeekMill mad he's ...</td>\n",
              "      <td>figurative</td>\n",
              "      <td>üòÇ</td>\n",
              "      <td>joy</td>\n",
              "      <td>joy</td>\n",
              "      <td>anger</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>28</td>\n",
              "      <td>Gotta let u in on what u missed out on #irony ...</td>\n",
              "      <td>figurative</td>\n",
              "      <td>üòä</td>\n",
              "      <td>joy</td>\n",
              "      <td>joy</td>\n",
              "      <td>joy</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0.1  Unnamed: 0  \\\n",
              "0             0          11   \n",
              "1             1          24   \n",
              "2             2          28   \n",
              "\n",
              "                                              tweets       class  \\\n",
              "0  That shitty feeling we all love so much üòä #sar...  figurative   \n",
              "1  @HOT97 it's pretty obvious @MeekMill mad he's ...  figurative   \n",
              "2  Gotta let u in on what u missed out on #irony ...  figurative   \n",
              "\n",
              "  primary_emoji emoji_emotion emotion_label hidden_emotion_label  \\\n",
              "0             üòä           joy           joy                anger   \n",
              "1             üòÇ           joy           joy                anger   \n",
              "2             üòä           joy           joy                  joy   \n",
              "\n",
              "   hidden_emotion_flag  emoji_text_sentiment_match  \n",
              "0                 True                       False  \n",
              "1                 True                       False  \n",
              "2                False                        True  "
            ]
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "DATASET 4: goemotions_final_with_6class_hidden.csv\n",
            "============================================================\n",
            "Shape: (4127, 10)\n",
            "\n",
            "Columns: ['Unnamed: 0', 'text', 'id', 'emotion_label', 'goemotions_gpt', 'emoji_emotion', 'text_emotion', 'hidden_flag', 'sentiment_match', 'hidden_emotion_label']\n",
            "\n",
            "First 3 rows:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "      <th>id</th>\n",
              "      <th>emotion_label</th>\n",
              "      <th>goemotions_gpt</th>\n",
              "      <th>emoji_emotion</th>\n",
              "      <th>text_emotion</th>\n",
              "      <th>hidden_flag</th>\n",
              "      <th>sentiment_match</th>\n",
              "      <th>hidden_emotion_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Nice! You and her would get along i bet. She l...</td>\n",
              "      <td>ee3ckgv</td>\n",
              "      <td>neutral</td>\n",
              "      <td>['amusement']</td>\n",
              "      <td>joy</td>\n",
              "      <td>joy</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Funny, the right only seems to say this about ...</td>\n",
              "      <td>ed5c74n</td>\n",
              "      <td>amusement</td>\n",
              "      <td>['amusement', 'disapproval']</td>\n",
              "      <td>surprise</td>\n",
              "      <td>anger</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>I love this sub reddit üòçüòÇ</td>\n",
              "      <td>ee55r8y</td>\n",
              "      <td>love</td>\n",
              "      <td>['amusement', 'approval']</td>\n",
              "      <td>joy</td>\n",
              "      <td>joy</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                                               text       id  \\\n",
              "0           0  Nice! You and her would get along i bet. She l...  ee3ckgv   \n",
              "1           1  Funny, the right only seems to say this about ...  ed5c74n   \n",
              "2           2                          I love this sub reddit üòçüòÇ  ee55r8y   \n",
              "\n",
              "  emotion_label                goemotions_gpt emoji_emotion text_emotion  \\\n",
              "0       neutral                 ['amusement']           joy          joy   \n",
              "1     amusement  ['amusement', 'disapproval']      surprise        anger   \n",
              "2          love     ['amusement', 'approval']           joy          joy   \n",
              "\n",
              "   hidden_flag  sentiment_match hidden_emotion_label  \n",
              "0        False             True                  joy  \n",
              "1         True            False                anger  \n",
              "2        False             True                  joy  "
            ]
          }
        }
      ],
      "id": "855d70cb"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"LABEL DISTRIBUTIONS ANALYSIS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Target columns for model training\n",
        "target_cols = ['hidden_emotion_label', 'hidden_emotion_flag', 'emoji_text_sentiment_match']\n",
        "\n",
        "for i, (name, df) in enumerate([\n",
        "    (\"filter_labeled_v2\", df1), \n",
        "    (\"hidden_emotion_dataset\", df2), \n",
        "    (\"tweets_labeled\", df3),\n",
        "    (\"goemotions_final_with_6class_hidden\", df4)\n",
        "], 1):\n",
        "    print(f\"\\n{'='*40}\")\n",
        "    print(f\"DATASET {i}: {name}\")\n",
        "    print(f\"{'='*40}\")\n",
        "    \n",
        "    # Handle different column names for goemotions dataset\n",
        "    if name == \"goemotions_final_with_6class_hidden\":\n",
        "        hidden_flag_col = 'hidden_flag' if 'hidden_flag' in df.columns else 'hidden_emotion_flag'\n",
        "        sentiment_col = 'sentiment_match' if 'sentiment_match' in df.columns else 'emoji_text_sentiment_match'\n",
        "    else:\n",
        "        hidden_flag_col = 'hidden_emotion_flag'\n",
        "        sentiment_col = 'emoji_text_sentiment_match'\n",
        "    \n",
        "    print(f\"\\nhidden_emotion_label distribution:\")\n",
        "    print(df['hidden_emotion_label'].value_counts())\n",
        "    \n",
        "    print(f\"\\nhidden_emotion_flag distribution:\")\n",
        "    print(df[hidden_flag_col].value_counts())\n",
        "    \n",
        "    print(f\"\\nemoji_text_sentiment_match distribution:\")\n",
        "    if sentiment_col in df.columns:\n",
        "        print(df[sentiment_col].value_counts())\n",
        "    else:\n",
        "        print(\"Column not found in this dataset\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "LABEL DISTRIBUTIONS ANALYSIS\n",
            "============================================================\n",
            "\n",
            "========================================\n",
            "DATASET 1: filter_labeled_v2\n",
            "========================================\n",
            "\n",
            "hidden_emotion_label distribution:\n",
            "hidden_emotion_label\n",
            "joy         676\n",
            "sadness     315\n",
            "love        123\n",
            "anger        59\n",
            "fear         17\n",
            "surprise      2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "hidden_emotion_flag distribution:\n",
            "hidden_emotion_flag\n",
            "False    860\n",
            "True     332\n",
            "Name: count, dtype: int64\n",
            "\n",
            "emoji_text_sentiment_match distribution:\n",
            "emoji_text_sentiment_match\n",
            "True     858\n",
            "False    334\n",
            "Name: count, dtype: int64\n",
            "\n",
            "========================================\n",
            "DATASET 2: hidden_emotion_dataset\n",
            "========================================\n",
            "\n",
            "hidden_emotion_label distribution:\n",
            "hidden_emotion_label\n",
            "fear        418\n",
            "anger       407\n",
            "sadness     404\n",
            "surprise    263\n",
            "joy         256\n",
            "love        252\n",
            "Name: count, dtype: int64\n",
            "\n",
            "hidden_emotion_flag distribution:\n",
            "hidden_emotion_flag\n",
            "False    1100\n",
            "True      900\n",
            "Name: count, dtype: int64\n",
            "\n",
            "emoji_text_sentiment_match distribution:\n",
            "emoji_text_sentiment_match\n",
            "True     1100\n",
            "False     900\n",
            "Name: count, dtype: int64\n",
            "\n",
            "========================================\n",
            "DATASET 3: tweets_labeled\n",
            "========================================\n",
            "\n",
            "hidden_emotion_label distribution:\n",
            "hidden_emotion_label\n",
            "anger       1489\n",
            "joy         1333\n",
            "sadness      619\n",
            "love          68\n",
            "fear          37\n",
            "surprise      17\n",
            "Name: count, dtype: int64\n",
            "\n",
            "hidden_emotion_flag distribution:\n",
            "hidden_emotion_flag\n",
            "True     2308\n",
            "False    1255\n",
            "Name: count, dtype: int64\n",
            "\n",
            "emoji_text_sentiment_match distribution:\n",
            "emoji_text_sentiment_match\n",
            "False    2310\n",
            "True     1253\n",
            "Name: count, dtype: int64\n",
            "\n",
            "========================================\n",
            "DATASET 4: goemotions_final_with_6class_hidden\n",
            "========================================\n",
            "\n",
            "hidden_emotion_label distribution:\n",
            "hidden_emotion_label\n",
            "joy         1812\n",
            "sadness     1526\n",
            "love         387\n",
            "anger        336\n",
            "fear          35\n",
            "surprise      31\n",
            "Name: count, dtype: int64\n",
            "\n",
            "hidden_emotion_flag distribution:\n",
            "hidden_flag\n",
            "False    2504\n",
            "True     1623\n",
            "Name: count, dtype: int64\n",
            "\n",
            "emoji_text_sentiment_match distribution:\n",
            "sentiment_match\n",
            "True     2483\n",
            "False    1644\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "id": "33fdedb0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Identify common columns needed for training\n",
        "print(\"=\" * 60)\n",
        "print(\"MERGING STRATEGY\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Essential columns for hidden emotion detection model\n",
        "essential_cols = ['text', 'hidden_emotion_label', 'hidden_emotion_flag']\n",
        "optional_cols = ['emoji_text_sentiment_match', 'emotion_label', 'primary_emoji', 'emoji_emotion']\n",
        "\n",
        "# Standardize column names\n",
        "# Dataset 1: message_text -> text\n",
        "# Dataset 2: message_text -> text  \n",
        "# Dataset 3: tweets -> text\n",
        "# Dataset 4: goemotions_final_with_6class_hidden.csv - map columns appropriately\n",
        "\n",
        "df1_clean = df1[['message_text', 'hidden_emotion_label', 'hidden_emotion_flag', \n",
        "                  'emoji_text_sentiment_match', 'emotion_label', 'primary_emoji', 'emoji_emotion']].copy()\n",
        "df1_clean.rename(columns={'message_text': 'text'}, inplace=True)\n",
        "df1_clean['source'] = 'tiktok_labeled'\n",
        "\n",
        "df2_clean = df2[['message_text', 'hidden_emotion_label', 'hidden_emotion_flag', \n",
        "                  'emoji_text_sentiment_match', 'emotion_label']].copy()\n",
        "df2_clean.rename(columns={'message_text': 'text'}, inplace=True)\n",
        "# df2 doesn't have primary_emoji and emoji_emotion, extract from emojis column\n",
        "df2_clean['primary_emoji'] = df2['emojis'].apply(lambda x: x[0] if isinstance(x, str) and len(x) > 0 else None)\n",
        "df2_clean['emoji_emotion'] = None  # Will be derived later if needed\n",
        "df2_clean['source'] = 'synthetic'\n",
        "\n",
        "df3_clean = df3[['tweets', 'hidden_emotion_label', 'hidden_emotion_flag', \n",
        "                  'emoji_text_sentiment_match', 'emotion_label', 'primary_emoji', 'emoji_emotion']].copy()\n",
        "df3_clean.rename(columns={'tweets': 'text'}, inplace=True)\n",
        "df3_clean['source'] = 'tweets'\n",
        "\n",
        "# Dataset 4: GoEmotions - map columns: hidden_flag -> hidden_emotion_flag, sentiment_match -> emoji_text_sentiment_match\n",
        "# text_emotion -> emotion_label, no primary_emoji column\n",
        "df4_clean = df4[['text', 'hidden_emotion_label']].copy()\n",
        "df4_clean['hidden_emotion_flag'] = df4['hidden_flag'] if 'hidden_flag' in df4.columns else False\n",
        "df4_clean['emoji_text_sentiment_match'] = df4['sentiment_match'] if 'sentiment_match' in df4.columns else False\n",
        "df4_clean['emotion_label'] = df4['text_emotion'] if 'text_emotion' in df4.columns else df4.get('emotion_label', None)\n",
        "df4_clean['primary_emoji'] = None  # GoEmotions doesn't have primary_emoji\n",
        "df4_clean['emoji_emotion'] = df4['emoji_emotion'] if 'emoji_emotion' in df4.columns else None\n",
        "df4_clean['source'] = 'goemotions'\n",
        "\n",
        "print(f\"Dataset 1 (TikTok): {len(df1_clean)} rows\")\n",
        "print(f\"Dataset 2 (Synthetic): {len(df2_clean)} rows\")\n",
        "print(f\"Dataset 3 (Tweets): {len(df3_clean)} rows\")\n",
        "print(f\"Dataset 4 (GoEmotions): {len(df4_clean)} rows\")\n",
        "print(f\"\\nTotal rows after merge: {len(df1_clean) + len(df2_clean) + len(df3_clean) + len(df4_clean)}\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "MERGING STRATEGY\n",
            "============================================================\n",
            "Dataset 1 (TikTok): 1192 rows\n",
            "Dataset 2 (Synthetic): 2000 rows\n",
            "Dataset 3 (Tweets): 3563 rows\n",
            "Dataset 4 (GoEmotions): 4127 rows\n",
            "\n",
            "Total rows after merge: 10882\n"
          ]
        }
      ],
      "id": "5435df3a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Merge all datasets (including GoEmotions)\n",
        "merged_df = pd.concat([df1_clean, df2_clean, df3_clean, df4_clean], ignore_index=True)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"MERGED DATASET OVERVIEW\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nShape: {merged_df.shape}\")\n",
        "print(f\"\\nColumns: {list(merged_df.columns)}\")\n",
        "\n",
        "# Check for missing values\n",
        "print(f\"\\nMissing values:\")\n",
        "print(merged_df.isnull().sum())\n",
        "\n",
        "# Sample of merged data\n",
        "print(f\"\\nSample rows from merged dataset:\")\n",
        "display(merged_df.sample(5, random_state=42))\n",
        "merged_df.to_csv(\"merged_dataset.csv\",index=False)\n",
        "\n",
        "# Optional: log merged dataset to MLflow for data lineage\n",
        "try:\n",
        "    import mlflow\n",
        "    from mlflow_config import init_mlflow\n",
        "    from mlflow_utils import log_dataset_artifact\n",
        "    init_mlflow()\n",
        "    with mlflow.start_run(run_name=\"merge_data\"):\n",
        "        mlflow.log_param(\"num_rows\", len(merged_df))\n",
        "        mlflow.log_param(\"sources\", \"filter_labeled_v2,hidden_emotion_dataset,tweet_labeled3,goemotions\")\n",
        "        log_dataset_artifact(\"merged_dataset.csv\", \"data\")\n",
        "except Exception as e:\n",
        "    print(\"MLflow data logging skipped:\", e)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "MERGED DATASET OVERVIEW\n",
            "============================================================\n",
            "\n",
            "Shape: (10882, 8)\n",
            "\n",
            "Columns: ['text', 'hidden_emotion_label', 'hidden_emotion_flag', 'emoji_text_sentiment_match', 'emotion_label', 'primary_emoji', 'emoji_emotion', 'source']\n",
            "\n",
            "Missing values:\n",
            "text                             0\n",
            "hidden_emotion_label             0\n",
            "hidden_emotion_flag              0\n",
            "emoji_text_sentiment_match       0\n",
            "emotion_label                    0\n",
            "primary_emoji                 4127\n",
            "emoji_emotion                 2000\n",
            "source                           0\n",
            "dtype: int64\n",
            "\n",
            "Sample rows from merged dataset:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>hidden_emotion_label</th>\n",
              "      <th>hidden_emotion_flag</th>\n",
              "      <th>emoji_text_sentiment_match</th>\n",
              "      <th>emotion_label</th>\n",
              "      <th>primary_emoji</th>\n",
              "      <th>emoji_emotion</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4899</th>\n",
              "      <td>*their way #irony #2-1 #üòÇ #üíã https://t.co/Fcp4...</td>\n",
              "      <td>joy</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>joy</td>\n",
              "      <td>üòÇ</td>\n",
              "      <td>joy</td>\n",
              "      <td>tweets</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7603</th>\n",
              "      <td>Boys this team is üî•üöí</td>\n",
              "      <td>joy</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>joy</td>\n",
              "      <td>None</td>\n",
              "      <td>joy</td>\n",
              "      <td>goemotions</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3813</th>\n",
              "      <td>@EFCKingy I know. That's how I meant it üòÑ comp...</td>\n",
              "      <td>anger</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>joy</td>\n",
              "      <td>üòÑ</td>\n",
              "      <td>joy</td>\n",
              "      <td>tweets</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1803</th>\n",
              "      <td>Re bad sleep last brb night. shook @sam. üòû sur...</td>\n",
              "      <td>surprise</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>sadness</td>\n",
              "      <td>üòû</td>\n",
              "      <td>None</td>\n",
              "      <td>synthetic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1576</th>\n",
              "      <td>rough day brb üò≥ at home rn. feels bad @sam. fe...</td>\n",
              "      <td>sadness</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>surprise</td>\n",
              "      <td>üò≥</td>\n",
              "      <td>None</td>\n",
              "      <td>synthetic</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text hidden_emotion_label  \\\n",
              "4899  *their way #irony #2-1 #üòÇ #üíã https://t.co/Fcp4...                  joy   \n",
              "7603                               Boys this team is üî•üöí                  joy   \n",
              "3813  @EFCKingy I know. That's how I meant it üòÑ comp...                anger   \n",
              "1803  Re bad sleep last brb night. shook @sam. üòû sur...             surprise   \n",
              "1576  rough day brb üò≥ at home rn. feels bad @sam. fe...              sadness   \n",
              "\n",
              "      hidden_emotion_flag  emoji_text_sentiment_match emotion_label  \\\n",
              "4899                False                        True           joy   \n",
              "7603                False                        True           joy   \n",
              "3813                 True                       False           joy   \n",
              "1803                 True                       False       sadness   \n",
              "1576                 True                       False      surprise   \n",
              "\n",
              "     primary_emoji emoji_emotion      source  \n",
              "4899             üòÇ           joy      tweets  \n",
              "7603          None           joy  goemotions  \n",
              "3813             üòÑ           joy      tweets  \n",
              "1803             üòû          None   synthetic  \n",
              "1576             üò≥          None   synthetic  "
            ]
          }
        }
      ],
      "id": "eae301eb"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import re\n",
        "\n",
        "# Simple emoji regex covering most common emoji ranges\n",
        "emoji_pattern = re.compile(\n",
        "    '['\n",
        "    '\\U0001F300-\\U0001F5FF'  # symbols & pictographs\n",
        "    '\\U0001F600-\\U0001F64F'  # emoticons\n",
        "    '\\U0001F680-\\U0001F6FF'  # transport & map\n",
        "    '\\U0001F700-\\U0001F77F'  # alchemical symbols\n",
        "    '\\U0001F780-\\U0001F7FF'  # geometric shapes extended\n",
        "    '\\U0001F800-\\U0001F8FF'  # supplemental arrows\n",
        "    '\\U0001F900-\\U0001F9FF'  # supplemental symbols & pictographs\n",
        "    '\\U0001FA00-\\U0001FAFF'  # symbols & pictographs extended-A\n",
        "    '\\u2600-\\u26FF'          # misc symbols\n",
        "    '\\u2700-\\u27BF'          # dingbats\n",
        "    ']',\n",
        "    flags=re.UNICODE\n",
        ")\n",
        "\n",
        "def extract_primary_emoji_from_text(text: str):\n",
        "    if not isinstance(text, str):\n",
        "        return None\n",
        "    m = emoji_pattern.search(text)\n",
        "    if not m:\n",
        "        return None\n",
        "    # If the match is a multi-char emoji sequence, take the whole match\n",
        "    return m.group(0)\n",
        "\n",
        "# Only fill where primary_emoji is currently missing\n",
        "mask = merged_df['primary_emoji'].isna()\n",
        "merged_df.loc[mask, 'primary_emoji'] = (\n",
        "    merged_df.loc[mask, 'text'].apply(extract_primary_emoji_from_text)\n",
        ")\n",
        "\n",
        "# Optional: check remaining missing values\n",
        "print(merged_df['primary_emoji'].isnull().sum(), \"rows still without primary_emoji\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "144 rows still without primary_emoji\n"
          ]
        }
      ],
      "id": "d1302c79"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Merge all datasets (including GoEmotions)\n",
        "\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"MERGED DATASET OVERVIEW\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nShape: {merged_df.shape}\")\n",
        "print(f\"\\nColumns: {list(merged_df.columns)}\")\n",
        "\n",
        "# Check for missing values\n",
        "print(f\"\\nMissing values:\")\n",
        "print(merged_df.isnull().sum())\n",
        "\n",
        "# Sample of merged data\n",
        "print(f\"\\nSample rows from merged dataset:\")\n",
        "display(merged_df.sample(5, random_state=42))\n",
        "merged_df.to_csv(\"merged_dataset.csv\",index=False)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "MERGED DATASET OVERVIEW\n",
            "============================================================\n",
            "\n",
            "Shape: (10882, 8)\n",
            "\n",
            "Columns: ['text', 'hidden_emotion_label', 'hidden_emotion_flag', 'emoji_text_sentiment_match', 'emotion_label', 'primary_emoji', 'emoji_emotion', 'source']\n",
            "\n",
            "Missing values:\n",
            "text                             0\n",
            "hidden_emotion_label             0\n",
            "hidden_emotion_flag              0\n",
            "emoji_text_sentiment_match       0\n",
            "emotion_label                    0\n",
            "primary_emoji                  144\n",
            "emoji_emotion                 2000\n",
            "source                           0\n",
            "dtype: int64\n",
            "\n",
            "Sample rows from merged dataset:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>hidden_emotion_label</th>\n",
              "      <th>hidden_emotion_flag</th>\n",
              "      <th>emoji_text_sentiment_match</th>\n",
              "      <th>emotion_label</th>\n",
              "      <th>primary_emoji</th>\n",
              "      <th>emoji_emotion</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4899</th>\n",
              "      <td>*their way #irony #2-1 #üòÇ #üíã https://t.co/Fcp4...</td>\n",
              "      <td>joy</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>joy</td>\n",
              "      <td>üòÇ</td>\n",
              "      <td>joy</td>\n",
              "      <td>tweets</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7603</th>\n",
              "      <td>Boys this team is üî•üöí</td>\n",
              "      <td>joy</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>joy</td>\n",
              "      <td>üî•</td>\n",
              "      <td>joy</td>\n",
              "      <td>goemotions</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3813</th>\n",
              "      <td>@EFCKingy I know. That's how I meant it üòÑ comp...</td>\n",
              "      <td>anger</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>joy</td>\n",
              "      <td>üòÑ</td>\n",
              "      <td>joy</td>\n",
              "      <td>tweets</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1803</th>\n",
              "      <td>Re bad sleep last brb night. shook @sam. üòû sur...</td>\n",
              "      <td>surprise</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>sadness</td>\n",
              "      <td>üòû</td>\n",
              "      <td>None</td>\n",
              "      <td>synthetic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1576</th>\n",
              "      <td>rough day brb üò≥ at home rn. feels bad @sam. fe...</td>\n",
              "      <td>sadness</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>surprise</td>\n",
              "      <td>üò≥</td>\n",
              "      <td>None</td>\n",
              "      <td>synthetic</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text hidden_emotion_label  \\\n",
              "4899  *their way #irony #2-1 #üòÇ #üíã https://t.co/Fcp4...                  joy   \n",
              "7603                               Boys this team is üî•üöí                  joy   \n",
              "3813  @EFCKingy I know. That's how I meant it üòÑ comp...                anger   \n",
              "1803  Re bad sleep last brb night. shook @sam. üòû sur...             surprise   \n",
              "1576  rough day brb üò≥ at home rn. feels bad @sam. fe...              sadness   \n",
              "\n",
              "      hidden_emotion_flag  emoji_text_sentiment_match emotion_label  \\\n",
              "4899                False                        True           joy   \n",
              "7603                False                        True           joy   \n",
              "3813                 True                       False           joy   \n",
              "1803                 True                       False       sadness   \n",
              "1576                 True                       False      surprise   \n",
              "\n",
              "     primary_emoji emoji_emotion      source  \n",
              "4899             üòÇ           joy      tweets  \n",
              "7603             üî•           joy  goemotions  \n",
              "3813             üòÑ           joy      tweets  \n",
              "1803             üòû          None   synthetic  \n",
              "1576             üò≥          None   synthetic  "
            ]
          }
        }
      ],
      "id": "4844dde7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Final distribution analysis\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# 1. Hidden emotion label distribution\n",
        "ax1 = axes[0, 0]\n",
        "emotion_counts = merged_df['hidden_emotion_label'].value_counts()\n",
        "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7', '#DDA0DD']\n",
        "ax1.bar(emotion_counts.index, emotion_counts.values, color=colors)\n",
        "ax1.set_title('Hidden Emotion Label Distribution', fontsize=12, fontweight='bold')\n",
        "ax1.set_xlabel('Emotion')\n",
        "ax1.set_ylabel('Count')\n",
        "for i, v in enumerate(emotion_counts.values):\n",
        "    ax1.text(i, v + 50, f'{v}\\n({v/len(merged_df)*100:.1f}%)', ha='center', fontsize=9)\n",
        "\n",
        "# 2. Hidden emotion flag distribution\n",
        "ax2 = axes[0, 1]\n",
        "flag_counts = merged_df['hidden_emotion_flag'].value_counts()\n",
        "ax2.pie(flag_counts.values, labels=['No Hidden Emotion', 'Has Hidden Emotion'], \n",
        "        autopct='%1.1f%%', colors=['#90EE90', '#FFB347'], explode=[0, 0.05])\n",
        "ax2.set_title('Hidden Emotion Flag Distribution', fontsize=12, fontweight='bold')\n",
        "\n",
        "# 3. Source distribution\n",
        "ax3 = axes[1, 0]\n",
        "source_counts = merged_df['source'].value_counts()\n",
        "ax3.bar(source_counts.index, source_counts.values, color=['#FF9999', '#66B2FF', '#99FF99', '#FFB6C1'])\n",
        "ax3.set_title('Data Source Distribution', fontsize=12, fontweight='bold')\n",
        "ax3.set_xlabel('Source')\n",
        "ax3.set_ylabel('Count')\n",
        "for i, v in enumerate(source_counts.values):\n",
        "    ax3.text(i, v + 50, f'{v}', ha='center', fontsize=10)\n",
        "\n",
        "# 4. Hidden emotion by source\n",
        "ax4 = axes[1, 1]\n",
        "cross_tab = pd.crosstab(merged_df['source'], merged_df['hidden_emotion_label'])\n",
        "cross_tab.plot(kind='bar', ax=ax4, color=colors)\n",
        "ax4.set_title('Hidden Emotion by Source', fontsize=12, fontweight='bold')\n",
        "ax4.set_xlabel('Source')\n",
        "ax4.set_ylabel('Count')\n",
        "ax4.legend(title='Emotion', bbox_to_anchor=(1.02, 1))\n",
        "ax4.tick_params(axis='x', rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"SUMMARY STATISTICS\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nTotal samples: {len(merged_df)}\")\n",
        "print(f\"\\nHidden emotion distribution:\")\n",
        "for emotion, count in emotion_counts.items():\n",
        "    print(f\"  {emotion}: {count} ({count/len(merged_df)*100:.1f}%)\")\n",
        "    \n",
        "print(f\"\\nHidden emotion flag:\")\n",
        "print(f\"  True (has hidden emotion): {flag_counts.get(True, 0)} ({flag_counts.get(True, 0)/len(merged_df)*100:.1f}%)\")\n",
        "print(f\"  False (no hidden emotion): {flag_counts.get(False, 0)} ({flag_counts.get(False, 0)/len(merged_df)*100:.1f}%)\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'matplotlib'",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Final distribution analysis\u001b[39;00m\n\u001b[32m      4\u001b[39m fig, axes = plt.subplots(\u001b[32m2\u001b[39m, \u001b[32m2\u001b[39m, figsize=(\u001b[32m14\u001b[39m, \u001b[32m10\u001b[39m))\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
          ]
        }
      ],
      "id": "ef8626c6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Clean and prepare final dataset for model training\n",
        "print(\"=\" * 60)\n",
        "print(\"PREPARING FINAL DATASET FOR TRAINING\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Select all required columns for training (essential + optional)\n",
        "all_cols = ['text', 'hidden_emotion_label', 'hidden_emotion_flag', \n",
        "            'emoji_text_sentiment_match', 'emotion_label', 'primary_emoji', 'emoji_emotion']\n",
        "training_df = merged_df[all_cols].copy()\n",
        "\n",
        "# Clean text - remove only rows with empty text (keep NaN in emoji_emotion)\n",
        "training_df = training_df[training_df['text'].notna()]\n",
        "training_df = training_df[training_df['text'].str.strip() != '']\n",
        "\n",
        "# Convert boolean to int for model training\n",
        "training_df['hidden_emotion_flag'] = training_df['hidden_emotion_flag'].astype(int)\n",
        "training_df['emoji_text_sentiment_match'] = training_df['emoji_text_sentiment_match'].astype(int)\n",
        "\n",
        "print(f\"\\nFinal training dataset shape: {training_df.shape}\")\n",
        "print(f\"\\nLabel encoding for hidden_emotion_label:\")\n",
        "label_mapping = {label: idx for idx, label in enumerate(sorted(training_df['hidden_emotion_label'].unique()))}\n",
        "print(label_mapping)\n",
        "\n",
        "# Add numeric label column\n",
        "training_df['hidden_emotion_id'] = training_df['hidden_emotion_label'].map(label_mapping)\n",
        "\n",
        "print(f\"\\nSample of final training data:\")\n",
        "display(training_df.head(10))\n",
        "\n",
        "# Save to CSV\n",
        "output_path = os.path.join(base_path, \"merged_training_dataset.csv\")\n",
        "training_df.to_csv(output_path, index=False)\n",
        "print(f\"\\n‚úÖ Saved training dataset to: {output_path}\")\n",
        "\n",
        "# Also save the full merged dataset with all columns\n",
        "full_output_path = os.path.join(base_path, \"merged_full_dataset.csv\")\n",
        "merged_df.to_csv(full_output_path, index=False)\n",
        "print(f\"‚úÖ Saved full dataset to: {full_output_path}\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "PREPARING FINAL DATASET FOR TRAINING\n",
            "============================================================\n",
            "\n",
            "Final training dataset shape: (10882, 7)\n",
            "\n",
            "Label encoding for hidden_emotion_label:\n",
            "{'anger': 0, 'fear': 1, 'joy': 2, 'love': 3, 'sadness': 4, 'surprise': 5}\n",
            "\n",
            "Sample of final training data:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>hidden_emotion_label</th>\n",
              "      <th>hidden_emotion_flag</th>\n",
              "      <th>emoji_text_sentiment_match</th>\n",
              "      <th>emotion_label</th>\n",
              "      <th>primary_emoji</th>\n",
              "      <th>emoji_emotion</th>\n",
              "      <th>hidden_emotion_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"Woah did you draw that?\"\\nNo, I Printed it. O...</td>\n",
              "      <td>joy</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>anger</td>\n",
              "      <td>üëπ</td>\n",
              "      <td>anger</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I CANT WITH THESE COMMENTSüò≠üôè</td>\n",
              "      <td>anger</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>sadness</td>\n",
              "      <td>üò≠</td>\n",
              "      <td>sadness</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\" Oh sorry, were you sleeping? \" No, I'm summo...</td>\n",
              "      <td>joy</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>anger</td>\n",
              "      <td>üíÄ</td>\n",
              "      <td>anger</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>are u laying down? NO IM FLYINGüî•üòÄ</td>\n",
              "      <td>joy</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>anger</td>\n",
              "      <td>üî•</td>\n",
              "      <td>anger</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>‚ÄúLo sai che per avere i soldi noi dobbiamo lav...</td>\n",
              "      <td>sadness</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>sadness</td>\n",
              "      <td>üòî</td>\n",
              "      <td>sadness</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>‚ÄúAre you sleeping rn ‚Äú no ofc not I‚Äôm hiding i...</td>\n",
              "      <td>fear</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>sadness</td>\n",
              "      <td>üòî</td>\n",
              "      <td>sadness</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>When moms says ‚Äúya llegaste?‚Äù ‚Ä¶. No ya me fui üôÇ</td>\n",
              "      <td>sadness</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>joy</td>\n",
              "      <td>üôÇ</td>\n",
              "      <td>joy</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>My parents made me become sarcastic that it‚Äôs ...</td>\n",
              "      <td>joy</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>sadness</td>\n",
              "      <td>üò≠</td>\n",
              "      <td>sadness</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>‚ÄúAre u in the bathroom?‚Äù NO IM ON FLIPPIN MARS üíî</td>\n",
              "      <td>anger</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>sadness</td>\n",
              "      <td>üíî</td>\n",
              "      <td>sadness</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Fighting your demons are another type of battle ü§£</td>\n",
              "      <td>sadness</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>joy</td>\n",
              "      <td>ü§£</td>\n",
              "      <td>joy</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text hidden_emotion_label  \\\n",
              "0  \"Woah did you draw that?\"\\nNo, I Printed it. O...                  joy   \n",
              "1                       I CANT WITH THESE COMMENTSüò≠üôè                anger   \n",
              "2  \" Oh sorry, were you sleeping? \" No, I'm summo...                  joy   \n",
              "3                  are u laying down? NO IM FLYINGüî•üòÄ                  joy   \n",
              "4  ‚ÄúLo sai che per avere i soldi noi dobbiamo lav...              sadness   \n",
              "5  ‚ÄúAre you sleeping rn ‚Äú no ofc not I‚Äôm hiding i...                 fear   \n",
              "6    When moms says ‚Äúya llegaste?‚Äù ‚Ä¶. No ya me fui üôÇ              sadness   \n",
              "7  My parents made me become sarcastic that it‚Äôs ...                  joy   \n",
              "8   ‚ÄúAre u in the bathroom?‚Äù NO IM ON FLIPPIN MARS üíî                anger   \n",
              "9  Fighting your demons are another type of battle ü§£              sadness   \n",
              "\n",
              "   hidden_emotion_flag  emoji_text_sentiment_match emotion_label  \\\n",
              "0                    1                           0         anger   \n",
              "1                    1                           0       sadness   \n",
              "2                    0                           1         anger   \n",
              "3                    0                           1         anger   \n",
              "4                    0                           1       sadness   \n",
              "5                    1                           0       sadness   \n",
              "6                    1                           0           joy   \n",
              "7                    1                           0       sadness   \n",
              "8                    1                           0       sadness   \n",
              "9                    1                           0           joy   \n",
              "\n",
              "  primary_emoji emoji_emotion  hidden_emotion_id  \n",
              "0             üëπ         anger                  2  \n",
              "1             üò≠       sadness                  0  \n",
              "2             üíÄ         anger                  2  \n",
              "3             üî•         anger                  2  \n",
              "4             üòî       sadness                  4  \n",
              "5             üòî       sadness                  1  \n",
              "6             üôÇ           joy                  4  \n",
              "7             üò≠       sadness                  2  \n",
              "8             üíî       sadness                  0  \n",
              "9             ü§£           joy                  4  "
            ]
          }
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'base_path' is not defined",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     28\u001b[39m display(training_df.head(\u001b[32m10\u001b[39m))\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Save to CSV\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m output_path = os.path.join(\u001b[43mbase_path\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33mmerged_training_dataset.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     32\u001b[39m training_df.to_csv(output_path, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     33\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m‚úÖ Saved training dataset to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mNameError\u001b[39m: name 'base_path' is not defined"
          ]
        }
      ],
      "id": "2d3559ee"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Dataset Analysis Summary\n",
        "\n",
        "### Dataset Sources:\n",
        "| Source | Rows | Description |\n",
        "|--------|------|-------------|\n",
        "| TikTok Labeled | 1,192 | Real TikTok comments with emoji-based labeling |\n",
        "| Synthetic | 2,000 | Synthetic data balanced across 6 emotions |\n",
        "| Tweets | 3,041 | Twitter data with sarcasm/irony markers |\n",
        "| GoEmotions | varies | GoEmotions dataset with 6-class hidden emotion labels |\n",
        "| **Total** | **varies** | Combined training dataset (includes GoEmotions) |\n",
        "\n",
        "### Key Findings:\n",
        "\n",
        "1. **Hidden Emotion Distribution:**\n",
        "   - Joy: 35.6% (2,220 samples)\n",
        "   - Anger: 28.7% (1,786 samples)  \n",
        "   - Sadness: 16.7% (1,041 samples)\n",
        "   - Fear: 7.5% (469 samples)\n",
        "   - Love: 7.1% (440 samples)\n",
        "   - Surprise: 4.4% (277 samples)\n",
        "\n",
        "2. **Hidden Emotion Flag:** ~50/50 split (balanced!)\n",
        "   - Has hidden emotion: 49.9%\n",
        "   - No hidden emotion: 50.1%\n",
        "\n",
        "3. **Imbalance Issues:**\n",
        "   - Fear, love, surprise are underrepresented\n",
        "   - Consider class weights or oversampling for training\n",
        "\n",
        "### Saved Files:\n",
        "- `merged_training_dataset.csv` - Essential columns for training (text, labels)\n",
        "- `merged_full_dataset.csv` - All columns including source info\n",
        "\n",
        "### Training Tasks:\n",
        "1. **Binary Classification:** `hidden_emotion_flag` (0/1)\n",
        "2. **Multi-class Classification:** `hidden_emotion_label` (6 classes)"
      ],
      "id": "2d16f63b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üß† Advanced Deep Neural Network for Hidden Emotion Detection\n",
        "\n",
        "## Architecture Overview:\n",
        "- **Base Model:** RoBERTa-base (transformer encoder)\n",
        "- **Multi-Task Learning:** Joint prediction of hidden emotion + flag\n",
        "- **Advanced Features:**\n",
        "  - Emoji embedding fusion\n",
        "  - Attention visualization\n",
        "  - Class-weighted focal loss for imbalanced data\n",
        "  - Gradient accumulation for effective larger batches"
      ],
      "id": "e79e781e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Install required packages\n",
        "!pip install transformers torch datasets accelerate scikit-learn emoji -q"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "e1c92e9e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import RobertaTokenizer, RobertaModel, get_linear_schedule_with_warmup\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Check device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
        "print(f\"üîß Using device: {device}\")\n",
        "\n",
        "# Load the merged training dataset\n",
        "df = pd.read_csv(\"/Users/Rivin/Desktop/untitled folder/Final/merged_training_dataset.csv\")\n",
        "print(f\"üìä Dataset shape: {df.shape}\")\n",
        "display(df.head())"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "addec560"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================================\n",
        "# DATA PREPARATION\n",
        "# ============================================================\n",
        "\n",
        "# Label mappings\n",
        "EMOTION_LABELS = ['anger', 'fear', 'joy', 'love', 'sadness', 'surprise']\n",
        "emotion2id = {e: i for i, e in enumerate(EMOTION_LABELS)}\n",
        "id2emotion = {i: e for e, i in emotion2id.items()}\n",
        "\n",
        "# Prepare data\n",
        "df['emotion_id'] = df['hidden_emotion_label'].map(emotion2id)\n",
        "df['flag'] = df['hidden_emotion_flag'].astype(int)\n",
        "\n",
        "# Train/Val/Test split (70/15/15)\n",
        "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42, stratify=df['emotion_id'])\n",
        "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df['emotion_id'])\n",
        "\n",
        "print(f\"üìä Train: {len(train_df)} | Val: {len(val_df)} | Test: {len(test_df)}\")\n",
        "print(f\"\\nüìà Train emotion distribution:\")\n",
        "print(train_df['hidden_emotion_label'].value_counts())"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "887d4675"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================================\n",
        "# CUSTOM DATASET CLASS\n",
        "# ============================================================\n",
        "\n",
        "class HiddenEmotionDataset(Dataset):\n",
        "    def __init__(self, texts, emotions, flags, tokenizer, max_length=128):\n",
        "        self.texts = texts.tolist()\n",
        "        self.emotions = emotions.tolist()\n",
        "        self.flags = flags.tolist()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        \n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        \n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(0),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
        "            'emotion_label': torch.tensor(self.emotions[idx], dtype=torch.long),\n",
        "            'flag_label': torch.tensor(self.flags[idx], dtype=torch.float)\n",
        "        }\n",
        "\n",
        "# Initialize tokenizer\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "print(\"‚úÖ Tokenizer loaded\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "c8393c37"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================================\n",
        "# ADVANCED MULTI-TASK HIDDEN EMOTION MODEL\n",
        "# ============================================================\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    \"\"\"Focal Loss for handling class imbalance\"\"\"\n",
        "    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "    \n",
        "    def forward(self, inputs, targets):\n",
        "        ce_loss = F.cross_entropy(inputs, targets, weight=self.alpha, reduction='none')\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n",
        "        \n",
        "        if self.reduction == 'mean':\n",
        "            return focal_loss.mean()\n",
        "        return focal_loss\n",
        "\n",
        "\n",
        "class MultiHeadAttentionPooling(nn.Module):\n",
        "    \"\"\"Multi-head attention pooling for sequence representation\"\"\"\n",
        "    def __init__(self, hidden_size, num_heads=8):\n",
        "        super().__init__()\n",
        "        self.attention = nn.MultiheadAttention(hidden_size, num_heads, batch_first=True)\n",
        "        self.query = nn.Parameter(torch.randn(1, 1, hidden_size))\n",
        "    \n",
        "    def forward(self, hidden_states, attention_mask):\n",
        "        batch_size = hidden_states.size(0)\n",
        "        query = self.query.expand(batch_size, -1, -1)\n",
        "        \n",
        "        # Create key padding mask (True = ignore)\n",
        "        key_padding_mask = (attention_mask == 0)\n",
        "        \n",
        "        attn_output, attn_weights = self.attention(\n",
        "            query, hidden_states, hidden_states,\n",
        "            key_padding_mask=key_padding_mask\n",
        "        )\n",
        "        return attn_output.squeeze(1), attn_weights\n",
        "\n",
        "\n",
        "class HiddenEmotionDetector(nn.Module):\n",
        "    \"\"\"\n",
        "    Advanced Multi-Task Transformer Model for Hidden Emotion Detection\n",
        "    \n",
        "    Features:\n",
        "    - RoBERTa encoder with frozen lower layers\n",
        "    - Multi-head attention pooling\n",
        "    - Separate task-specific heads with residual connections\n",
        "    - Dropout regularization throughout\n",
        "    \"\"\"\n",
        "    def __init__(self, num_emotions=6, dropout=0.3, freeze_layers=6):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Load pre-trained RoBERTa\n",
        "        self.roberta = RobertaModel.from_pretrained('roberta-base')\n",
        "        hidden_size = self.roberta.config.hidden_size  # 768\n",
        "        \n",
        "        # Freeze lower transformer layers for efficiency\n",
        "        for i, layer in enumerate(self.roberta.encoder.layer[:freeze_layers]):\n",
        "            for param in layer.parameters():\n",
        "                param.requires_grad = False\n",
        "        \n",
        "        # Multi-head attention pooling\n",
        "        self.attention_pooling = MultiHeadAttentionPooling(hidden_size, num_heads=8)\n",
        "        \n",
        "        # Shared representation layer\n",
        "        self.shared_layer = nn.Sequential(\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "            nn.LayerNorm(hidden_size),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "        \n",
        "        # Task 1: Hidden Emotion Classification Head (6 classes)\n",
        "        self.emotion_head = nn.Sequential(\n",
        "            nn.Linear(hidden_size, hidden_size // 2),\n",
        "            nn.LayerNorm(hidden_size // 2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_size // 2, hidden_size // 4),\n",
        "            nn.LayerNorm(hidden_size // 4),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_size // 4, num_emotions)\n",
        "        )\n",
        "        \n",
        "        # Task 2: Hidden Emotion Flag Head (binary)\n",
        "        self.flag_head = nn.Sequential(\n",
        "            nn.Linear(hidden_size, hidden_size // 2),\n",
        "            nn.LayerNorm(hidden_size // 2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_size // 2, 1)\n",
        "        )\n",
        "        \n",
        "        # Initialize weights\n",
        "        self._init_weights()\n",
        "    \n",
        "    def _init_weights(self):\n",
        "        for module in [self.shared_layer, self.emotion_head, self.flag_head]:\n",
        "            for m in module.modules():\n",
        "                if isinstance(m, nn.Linear):\n",
        "                    nn.init.xavier_uniform_(m.weight)\n",
        "                    if m.bias is not None:\n",
        "                        nn.init.zeros_(m.bias)\n",
        "    \n",
        "    def forward(self, input_ids, attention_mask, return_attention=False):\n",
        "        # Get RoBERTa outputs\n",
        "        outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        hidden_states = outputs.last_hidden_state  # (batch, seq_len, 768)\n",
        "        \n",
        "        # Multi-head attention pooling\n",
        "        pooled, attn_weights = self.attention_pooling(hidden_states, attention_mask)\n",
        "        \n",
        "        # Shared representation with residual\n",
        "        shared = self.shared_layer(pooled) + pooled\n",
        "        \n",
        "        # Task-specific outputs\n",
        "        emotion_logits = self.emotion_head(shared)\n",
        "        flag_logits = self.flag_head(shared).squeeze(-1)\n",
        "        \n",
        "        if return_attention:\n",
        "            return emotion_logits, flag_logits, attn_weights\n",
        "        return emotion_logits, flag_logits\n",
        "\n",
        "\n",
        "# Initialize model\n",
        "model = HiddenEmotionDetector(num_emotions=6, dropout=0.3, freeze_layers=6)\n",
        "model = model.to(device)\n",
        "\n",
        "# Count parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"üìä Total parameters: {total_params:,}\")\n",
        "print(f\"üìä Trainable parameters: {trainable_params:,}\")\n",
        "print(f\"üìä Frozen parameters: {total_params - trainable_params:,}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "dc2990f2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================================\n",
        "# TRAINING CONFIGURATION\n",
        "# ============================================================\n",
        "\n",
        "# Hyperparameters\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 10\n",
        "LEARNING_RATE = 2e-5\n",
        "WARMUP_RATIO = 0.1\n",
        "MAX_LENGTH = 128\n",
        "GRADIENT_ACCUMULATION_STEPS = 2\n",
        "EMOTION_LOSS_WEIGHT = 0.7  # Weight for emotion classification loss\n",
        "FLAG_LOSS_WEIGHT = 0.3     # Weight for flag prediction loss\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = HiddenEmotionDataset(\n",
        "    train_df['text'], train_df['emotion_id'], train_df['flag'], \n",
        "    tokenizer, MAX_LENGTH\n",
        ")\n",
        "val_dataset = HiddenEmotionDataset(\n",
        "    val_df['text'], val_df['emotion_id'], val_df['flag'], \n",
        "    tokenizer, MAX_LENGTH\n",
        ")\n",
        "test_dataset = HiddenEmotionDataset(\n",
        "    test_df['text'], test_df['emotion_id'], test_df['flag'], \n",
        "    tokenizer, MAX_LENGTH\n",
        ")\n",
        "\n",
        "# Create dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "\n",
        "print(f\"üì¶ Train batches: {len(train_loader)}\")\n",
        "print(f\"üì¶ Val batches: {len(val_loader)}\")\n",
        "print(f\"üì¶ Test batches: {len(test_loader)}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "01a24eb6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================================\n",
        "# LOSS FUNCTIONS & OPTIMIZER\n",
        "# ============================================================\n",
        "\n",
        "# Compute class weights for imbalanced data\n",
        "class_weights = compute_class_weight(\n",
        "    'balanced', \n",
        "    classes=np.array(list(range(6))), \n",
        "    y=train_df['emotion_id'].values\n",
        ")\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "print(f\"üìä Class weights: {dict(zip(EMOTION_LABELS, class_weights.cpu().numpy().round(2)))}\")\n",
        "\n",
        "# Focal Loss for emotion classification (handles imbalance)\n",
        "emotion_criterion = FocalLoss(alpha=class_weights, gamma=2.0)\n",
        "\n",
        "# Binary Cross Entropy for flag prediction\n",
        "flag_criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# Optimizer with different learning rates\n",
        "optimizer = torch.optim.AdamW([\n",
        "    {'params': model.roberta.parameters(), 'lr': LEARNING_RATE * 0.1},  # Lower LR for pretrained\n",
        "    {'params': model.attention_pooling.parameters(), 'lr': LEARNING_RATE},\n",
        "    {'params': model.shared_layer.parameters(), 'lr': LEARNING_RATE},\n",
        "    {'params': model.emotion_head.parameters(), 'lr': LEARNING_RATE},\n",
        "    {'params': model.flag_head.parameters(), 'lr': LEARNING_RATE},\n",
        "], weight_decay=0.01)\n",
        "\n",
        "# Learning rate scheduler with warmup\n",
        "total_steps = len(train_loader) * EPOCHS // GRADIENT_ACCUMULATION_STEPS\n",
        "warmup_steps = int(total_steps * WARMUP_RATIO)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n",
        "\n",
        "print(f\"üìà Total training steps: {total_steps}\")\n",
        "print(f\"üìà Warmup steps: {warmup_steps}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "afe68cf8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================================\n",
        "# TRAINING & EVALUATION FUNCTIONS\n",
        "# ============================================================\n",
        "\n",
        "def train_epoch(model, loader, optimizer, scheduler, emotion_criterion, flag_criterion, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    emotion_preds, emotion_labels = [], []\n",
        "    flag_preds, flag_labels = [], []\n",
        "    \n",
        "    progress_bar = tqdm(loader, desc=\"Training\")\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    for step, batch in enumerate(progress_bar):\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        emotion_label = batch['emotion_label'].to(device)\n",
        "        flag_label = batch['flag_label'].to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        emotion_logits, flag_logits = model(input_ids, attention_mask)\n",
        "        \n",
        "        # Compute losses\n",
        "        emotion_loss = emotion_criterion(emotion_logits, emotion_label)\n",
        "        flag_loss = flag_criterion(flag_logits, flag_label)\n",
        "        loss = EMOTION_LOSS_WEIGHT * emotion_loss + FLAG_LOSS_WEIGHT * flag_loss\n",
        "        loss = loss / GRADIENT_ACCUMULATION_STEPS\n",
        "        \n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        \n",
        "        # Gradient accumulation\n",
        "        if (step + 1) % GRADIENT_ACCUMULATION_STEPS == 0:\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "        \n",
        "        total_loss += loss.item() * GRADIENT_ACCUMULATION_STEPS\n",
        "        \n",
        "        # Collect predictions\n",
        "        emotion_preds.extend(emotion_logits.argmax(dim=1).cpu().numpy())\n",
        "        emotion_labels.extend(emotion_label.cpu().numpy())\n",
        "        flag_preds.extend((torch.sigmoid(flag_logits) > 0.5).cpu().numpy().astype(int))\n",
        "        flag_labels.extend(flag_label.cpu().numpy().astype(int))\n",
        "        \n",
        "        progress_bar.set_postfix({'loss': f'{loss.item() * GRADIENT_ACCUMULATION_STEPS:.4f}'})\n",
        "    \n",
        "    # Compute metrics\n",
        "    emotion_f1 = f1_score(emotion_labels, emotion_preds, average='weighted')\n",
        "    flag_f1 = f1_score(flag_labels, flag_preds, average='binary')\n",
        "    \n",
        "    return total_loss / len(loader), emotion_f1, flag_f1\n",
        "\n",
        "\n",
        "def evaluate(model, loader, emotion_criterion, flag_criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    emotion_preds, emotion_labels = [], []\n",
        "    flag_preds, flag_labels = [], []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(loader, desc=\"Evaluating\"):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            emotion_label = batch['emotion_label'].to(device)\n",
        "            flag_label = batch['flag_label'].to(device)\n",
        "            \n",
        "            emotion_logits, flag_logits = model(input_ids, attention_mask)\n",
        "            \n",
        "            emotion_loss = emotion_criterion(emotion_logits, emotion_label)\n",
        "            flag_loss = flag_criterion(flag_logits, flag_label)\n",
        "            loss = EMOTION_LOSS_WEIGHT * emotion_loss + FLAG_LOSS_WEIGHT * flag_loss\n",
        "            \n",
        "            total_loss += loss.item()\n",
        "            \n",
        "            emotion_preds.extend(emotion_logits.argmax(dim=1).cpu().numpy())\n",
        "            emotion_labels.extend(emotion_label.cpu().numpy())\n",
        "            flag_preds.extend((torch.sigmoid(flag_logits) > 0.5).cpu().numpy().astype(int))\n",
        "            flag_labels.extend(flag_label.cpu().numpy().astype(int))\n",
        "    \n",
        "    emotion_f1 = f1_score(emotion_labels, emotion_preds, average='weighted')\n",
        "    flag_f1 = f1_score(flag_labels, flag_preds, average='binary')\n",
        "    \n",
        "    return total_loss / len(loader), emotion_f1, flag_f1, emotion_preds, emotion_labels, flag_preds, flag_labels\n",
        "\n",
        "print(\"‚úÖ Training functions defined\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "31deadf2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================================\n",
        "# TRAINING LOOP\n",
        "# ============================================================\n",
        "\n",
        "print(\"üöÄ Starting Training...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "best_val_f1 = 0\n",
        "best_model_state = None\n",
        "history = {'train_loss': [], 'val_loss': [], 'train_emotion_f1': [], 'val_emotion_f1': [], \n",
        "           'train_flag_f1': [], 'val_flag_f1': []}\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"\\nüìÖ Epoch {epoch + 1}/{EPOCHS}\")\n",
        "    print(\"-\" * 40)\n",
        "    \n",
        "    # Training\n",
        "    train_loss, train_emotion_f1, train_flag_f1 = train_epoch(\n",
        "        model, train_loader, optimizer, scheduler, \n",
        "        emotion_criterion, flag_criterion, device\n",
        "    )\n",
        "    \n",
        "    # Validation\n",
        "    val_loss, val_emotion_f1, val_flag_f1, _, _, _, _ = evaluate(\n",
        "        model, val_loader, emotion_criterion, flag_criterion, device\n",
        "    )\n",
        "    \n",
        "    # Store history\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['val_loss'].append(val_loss)\n",
        "    history['train_emotion_f1'].append(train_emotion_f1)\n",
        "    history['val_emotion_f1'].append(val_emotion_f1)\n",
        "    history['train_flag_f1'].append(train_flag_f1)\n",
        "    history['val_flag_f1'].append(val_flag_f1)\n",
        "    \n",
        "    print(f\"üìâ Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
        "    print(f\"üéØ Train Emotion F1: {train_emotion_f1:.4f} | Val Emotion F1: {val_emotion_f1:.4f}\")\n",
        "    print(f\"üè≥Ô∏è Train Flag F1: {train_flag_f1:.4f} | Val Flag F1: {val_flag_f1:.4f}\")\n",
        "    \n",
        "    # Save best model\n",
        "    combined_f1 = 0.7 * val_emotion_f1 + 0.3 * val_flag_f1\n",
        "    if combined_f1 > best_val_f1:\n",
        "        best_val_f1 = combined_f1\n",
        "        best_model_state = model.state_dict().copy()\n",
        "        print(f\"‚úÖ New best model saved! Combined F1: {combined_f1:.4f}\")\n",
        "\n",
        "# Load best model\n",
        "model.load_state_dict(best_model_state)\n",
        "print(f\"\\nüèÜ Training complete! Best Combined F1: {best_val_f1:.4f}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "52d68e59"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================================\n",
        "# TRAINING VISUALIZATION\n",
        "# ============================================================\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "# Loss curves\n",
        "ax1 = axes[0]\n",
        "ax1.plot(history['train_loss'], label='Train Loss', marker='o')\n",
        "ax1.plot(history['val_loss'], label='Val Loss', marker='s')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax1.set_title('Training & Validation Loss')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Emotion F1 curves\n",
        "ax2 = axes[1]\n",
        "ax2.plot(history['train_emotion_f1'], label='Train F1', marker='o')\n",
        "ax2.plot(history['val_emotion_f1'], label='Val F1', marker='s')\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_ylabel('F1 Score')\n",
        "ax2.set_title('Emotion Classification F1')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# Flag F1 curves\n",
        "ax3 = axes[2]\n",
        "ax3.plot(history['train_flag_f1'], label='Train F1', marker='o')\n",
        "ax3.plot(history['val_flag_f1'], label='Val F1', marker='s')\n",
        "ax3.set_xlabel('Epoch')\n",
        "ax3.set_ylabel('F1 Score')\n",
        "ax3.set_title('Hidden Emotion Flag F1')\n",
        "ax3.legend()\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "ef97cedd"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================================\n",
        "# FINAL EVALUATION ON TEST SET\n",
        "# ============================================================\n",
        "\n",
        "print(\"üß™ Evaluating on Test Set...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "test_loss, test_emotion_f1, test_flag_f1, emotion_preds, emotion_labels, flag_preds, flag_labels = evaluate(\n",
        "    model, test_loader, emotion_criterion, flag_criterion, device\n",
        ")\n",
        "\n",
        "print(f\"\\nüìä TEST RESULTS\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Emotion Classification F1 (weighted): {test_emotion_f1:.4f}\")\n",
        "print(f\"Hidden Emotion Flag F1: {test_flag_f1:.4f}\")\n",
        "\n",
        "# Detailed classification reports\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"EMOTION CLASSIFICATION REPORT\")\n",
        "print(\"=\" * 60)\n",
        "print(classification_report(emotion_labels, emotion_preds, target_names=EMOTION_LABELS, digits=4))\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"HIDDEN EMOTION FLAG REPORT\")\n",
        "print(\"=\" * 60)\n",
        "print(classification_report(flag_labels, flag_preds, target_names=['No Hidden', 'Has Hidden'], digits=4))"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "88e0d65d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================================\n",
        "# CONFUSION MATRIX VISUALIZATION\n",
        "# ============================================================\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Emotion confusion matrix\n",
        "ax1 = axes[0]\n",
        "cm_emotion = confusion_matrix(emotion_labels, emotion_preds)\n",
        "sns.heatmap(cm_emotion, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=EMOTION_LABELS, yticklabels=EMOTION_LABELS, ax=ax1)\n",
        "ax1.set_xlabel('Predicted')\n",
        "ax1.set_ylabel('Actual')\n",
        "ax1.set_title('Hidden Emotion Classification\\nConfusion Matrix')\n",
        "\n",
        "# Flag confusion matrix\n",
        "ax2 = axes[1]\n",
        "cm_flag = confusion_matrix(flag_labels, flag_preds)\n",
        "sns.heatmap(cm_flag, annot=True, fmt='d', cmap='Greens',\n",
        "            xticklabels=['No Hidden', 'Has Hidden'], \n",
        "            yticklabels=['No Hidden', 'Has Hidden'], ax=ax2)\n",
        "ax2.set_xlabel('Predicted')\n",
        "ax2.set_ylabel('Actual')\n",
        "ax2.set_title('Hidden Emotion Flag\\nConfusion Matrix')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "3a1e00fd"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================================\n",
        "# INFERENCE FUNCTION WITH ATTENTION VISUALIZATION\n",
        "# ============================================================\n",
        "\n",
        "def predict_hidden_emotion(text, model, tokenizer, device, show_attention=False):\n",
        "    \"\"\"\n",
        "    Predict hidden emotion for a single text input\n",
        "    \n",
        "    Returns:\n",
        "        dict with predictions and confidence scores\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    \n",
        "    # Tokenize\n",
        "    encoding = tokenizer(\n",
        "        text,\n",
        "        truncation=True,\n",
        "        max_length=128,\n",
        "        padding='max_length',\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "    \n",
        "    input_ids = encoding['input_ids'].to(device)\n",
        "    attention_mask = encoding['attention_mask'].to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        emotion_logits, flag_logits, attn_weights = model(\n",
        "            input_ids, attention_mask, return_attention=True\n",
        "        )\n",
        "        \n",
        "        # Emotion prediction\n",
        "        emotion_probs = F.softmax(emotion_logits, dim=1).squeeze()\n",
        "        emotion_pred = emotion_probs.argmax().item()\n",
        "        emotion_confidence = emotion_probs[emotion_pred].item()\n",
        "        \n",
        "        # Flag prediction\n",
        "        flag_prob = torch.sigmoid(flag_logits).item()\n",
        "        has_hidden_emotion = flag_prob > 0.5\n",
        "    \n",
        "    result = {\n",
        "        'text': text,\n",
        "        'hidden_emotion': id2emotion[emotion_pred],\n",
        "        'emotion_confidence': emotion_confidence,\n",
        "        'emotion_probabilities': {id2emotion[i]: p.item() for i, p in enumerate(emotion_probs)},\n",
        "        'has_hidden_emotion': has_hidden_emotion,\n",
        "        'hidden_emotion_probability': flag_prob\n",
        "    }\n",
        "    \n",
        "    if show_attention:\n",
        "        # Get tokens for attention visualization\n",
        "        tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
        "        valid_len = attention_mask[0].sum().item()\n",
        "        result['attention_weights'] = attn_weights[0, 0, :valid_len].cpu().numpy()\n",
        "        result['tokens'] = tokens[:valid_len]\n",
        "    \n",
        "    return result\n",
        "\n",
        "\n",
        "# Test inference\n",
        "print(\"üîÆ Testing Inference Function\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "test_texts = [\n",
        "    \"I love how everyone ignores my messages üòä\",\n",
        "    \"Best day ever! Finally got promoted! üéâ\",\n",
        "    \"Sure, I'm totally fine with working overtime again üòä\",\n",
        "    \"Can't believe they canceled my favorite show üò≠\"\n",
        "]\n",
        "\n",
        "for text in test_texts:\n",
        "    result = predict_hidden_emotion(text, model, tokenizer, device)\n",
        "    print(f\"\\nüìù Text: {text}\")\n",
        "    print(f\"   üé≠ Hidden Emotion: {result['hidden_emotion']} ({result['emotion_confidence']:.2%})\")\n",
        "    print(f\"   üè≥Ô∏è Has Hidden Emotion: {result['has_hidden_emotion']} ({result['hidden_emotion_probability']:.2%})\")\n",
        "    print(f\"   üìä All probs: {', '.join([f'{e}: {p:.1%}' for e, p in result['emotion_probabilities'].items()])}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "b36e4044"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================================\n",
        "# SAVE MODEL\n",
        "# ============================================================\n",
        "\n",
        "import json\n",
        "\n",
        "# Save model weights\n",
        "model_save_path = \"/Users/Rivin/Desktop/untitled folder/Final/hidden_emotion_model.pt\"\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'emotion2id': emotion2id,\n",
        "    'id2emotion': id2emotion,\n",
        "    'config': {\n",
        "        'num_emotions': 6,\n",
        "        'dropout': 0.3,\n",
        "        'freeze_layers': 6,\n",
        "        'max_length': MAX_LENGTH\n",
        "    }\n",
        "}, model_save_path)\n",
        "\n",
        "# Save training history\n",
        "history_path = \"/Users/Rivin/Desktop/untitled folder/Final/training_history.json\"\n",
        "with open(history_path, 'w') as f:\n",
        "    json.dump(history, f)\n",
        "\n",
        "print(f\"‚úÖ Model saved to: {model_save_path}\")\n",
        "print(f\"‚úÖ Training history saved to: {history_path}\")\n",
        "\n",
        "# Model summary\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"üìä MODEL SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Architecture: RoBERTa-base + Multi-Head Attention Pooling\")\n",
        "print(f\"Tasks: Hidden Emotion (6-class) + Flag (binary)\")\n",
        "print(f\"Total Parameters: {total_params:,}\")\n",
        "print(f\"Trainable Parameters: {trainable_params:,}\")\n",
        "print(f\"Best Validation F1: {best_val_f1:.4f}\")\n",
        "print(f\"Test Emotion F1: {test_emotion_f1:.4f}\")\n",
        "print(f\"Test Flag F1: {test_flag_f1:.4f}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "97e57afa"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üèÜ Model Architecture Summary\n",
        "\n",
        "### HiddenEmotionDetector\n",
        "```\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ                    INPUT TEXT                                ‚îÇ\n",
        "‚îÇ              \"I love how everyone ignores me üòä\"             ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                            ‚îÇ\n",
        "                            ‚ñº\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ              RoBERTa Tokenizer (max_len=128)                ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                            ‚îÇ\n",
        "                            ‚ñº\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ                   RoBERTa Encoder                           ‚îÇ\n",
        "‚îÇ        (12 layers, 768 hidden, 6 frozen layers)             ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                            ‚îÇ\n",
        "                            ‚ñº\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ           Multi-Head Attention Pooling (8 heads)            ‚îÇ\n",
        "‚îÇ              (Learnable query + attention)                  ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                            ‚îÇ\n",
        "                            ‚ñº\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ                 Shared Layer + Residual                     ‚îÇ\n",
        "‚îÇ            (Linear ‚Üí LayerNorm ‚Üí GELU ‚Üí Dropout)            ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                     ‚îÇ                ‚îÇ\n",
        "                     ‚ñº                ‚ñº\n",
        "        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "        ‚îÇ  Emotion Head  ‚îÇ  ‚îÇ   Flag Head    ‚îÇ\n",
        "        ‚îÇ (768‚Üí384‚Üí192‚Üí6)‚îÇ  ‚îÇ  (768‚Üí384‚Üí1)   ‚îÇ\n",
        "        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                ‚îÇ                    ‚îÇ\n",
        "                ‚ñº                    ‚ñº\n",
        "        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "        ‚îÇ 6-class output ‚îÇ  ‚îÇ Binary output  ‚îÇ\n",
        "        ‚îÇ  (softmax)     ‚îÇ  ‚îÇ  (sigmoid)     ‚îÇ\n",
        "        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "```\n",
        "\n",
        "### Key Features:\n",
        "1. **Focal Loss** - Handles class imbalance (Œ≥=2.0)\n",
        "2. **Class Weights** - Computed from training distribution\n",
        "3. **Layer Freezing** - First 6 transformer layers frozen\n",
        "4. **Gradient Accumulation** - Effective batch size = 32\n",
        "5. **Warmup Scheduler** - Linear warmup + decay\n",
        "6. **Multi-Task Learning** - 70% emotion + 30% flag loss"
      ],
      "id": "381fb5f3"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}