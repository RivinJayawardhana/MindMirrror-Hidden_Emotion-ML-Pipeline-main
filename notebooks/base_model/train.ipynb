{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZJmV3Fld4HR",
        "outputId": "efee7564-9ae5-4afc-bc3f-5d03ec28fe28"
      },
      "source": [
        "# Core packages\n",
        "!pip install pandas numpy scikit-learn emoji\n",
        "\n",
        "# PyTorch (Colab usually has it, but just in case)\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# Hugging Face transformers\n",
        "!pip install transformers\n",
        "\n",
        "# For progress bars (optional but helpful)\n",
        "!pip install tqdm\n",
        "\n",
        "# For better model performance tracking (optional)\n",
        "!pip install wandb\n",
        "\n",
        "# If you want to use smaller models (optional)\n",
        "!pip install sentencepiece\n",
        "\n",
        "# For data visualization (optional)\n",
        "!pip install matplotlib seaborn\n",
        "\n",
        "# MLOps: experiment tracking and model registry\n",
        "!pip install mlflow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Collecting emoji\n",
            "  Downloading emoji-2.15.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading emoji-2.15.0-py3-none-any.whl (608 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m608.4/608.4 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: emoji\n",
            "Successfully installed emoji-2.15.0\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (0.23.1)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb) (8.3.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (3.1.45)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from wandb) (25.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb) (4.5.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.12.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from wandb) (6.0.3)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.32.4)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.47.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.12/dist-packages (from wandb) (4.15.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2025.11.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.12/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f09525107b50474ab191fb3bf47b2353",
            "8a2c0c7e821f4bb9a64cbdc0c12157f2",
            "aec0713e4f134811b948662d8393cba0",
            "a3be57c4cfa0418a93ed59770dd24ab5",
            "624eea62bc304262a8e5b0f470e5f0ac",
            "e8c8332ecf2249fe818a18acb23a55f1",
            "f19658c4a19444e2b4e3978ea2c778b1",
            "65f44fa0d83e487d9ae3d88523495861",
            "302dfdd733804e44935d01226552d7be",
            "f71d2cfbe42143bc85af0d7777127e77",
            "f84b99470a7249fc9017d5b658d1efac",
            "4890a92d817a4c0e9fe4bf5f4018c017",
            "7498bddc963d4b8b9db31e2de2d02c22",
            "726f00fd15b546e491ca74cbbdb3be37",
            "44403e71a4534f4cbab9396542eecf0a",
            "edf7791fbd5e472da26d7cab35ae9d40",
            "a24eb8385daa4e2f9a225e3cbc6535b3",
            "83a326aa0310428eb1871e1520381664",
            "7aa909d359d84dd0a82dfeb7e4cadf15",
            "df23d10249764f04a67fe098c1ac7498",
            "2c632ba3df3d46758b864d9603b8ab02",
            "62deda4525db4abd848c64ac27799dee",
            "92013bba4f0f4c5fb691abb492605567",
            "ac52380ebabb4e37b2d0c7aea66610c4",
            "a39e6e7b5ba84adab5d11a85a02116c3",
            "15947573fc1b4102acfb0c2726dbe173",
            "d3fb75c744e846be8d7cf4105b1ffe3c",
            "c6b05fcfb9e04163a8ea8ad4d49f89e7",
            "8dffd51e8a81414080523ec642bb165c",
            "20c05a5c278a4eb5851ce334208cbee3",
            "d06124359b1e42289721912eb73a5a0a",
            "cb1bff475dd34183851379e3702c858a",
            "290e9be44ac74d96a63b4f03582a2f77",
            "20154019142340fa808961e59c3efdbc",
            "fea955f11f554bc1b9f519ec2f49fb45",
            "d7b76130b4944799b8a0ee0616ae1524",
            "2ec114f6182947a1ac10c5adcd5e96e8",
            "b7a0e1d8e9dd4197b3b30cbbba90bd7b",
            "8b6965f22f174a79aa27b87a6991dc77",
            "3b63c02e35d147919e22b9e88c37181b",
            "f963410e974f4cf88fb93a60dadc57f2",
            "ddb62225a6904796adefa8c6885affde",
            "548ccbebd36b413aae2ccb8f0d36887c",
            "04bfe60e231b46a4bed4dffc950d7d3e",
            "94663506177040609a08c874cae771c9",
            "884da155e714426e835a372314d58eff",
            "f4d19f582752419c8b1298ab76ffe93a",
            "51e7ce55578746bca4afcd97f88dc321",
            "21b0ea8ed95b47b69a28db2c42d70c17",
            "6913fd51477e456c97653d19ebf3d1a2",
            "935e7d74ed6040fe980b18171b85b3f7",
            "0c39c35203ce4c379875615b50188d1c",
            "6434bd9e7a0a4ed6ad0bf6fd9d2a15ce",
            "70233b8c61764147bbeb4dbb2b40aa47",
            "5b28680865534b20b382ce42f4219af9"
          ]
        },
        "id": "X3BRrEr3g1YK",
        "outputId": "92f75a08-8c9d-463d-d0df-2e6cd29a1900"
      },
      "source": [
        "# ============================================================\n",
        "# 0) Imports\n",
        "# ============================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import math\n",
        "import emoji\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    accuracy_score,\n",
        "    precision_recall_fscore_support,\n",
        ")\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModel,\n",
        "    get_cosine_schedule_with_warmup,\n",
        "    get_linear_schedule_with_warmup,\n",
        ")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# ============================================================\n",
        "# MLflow: init tracking and experiment\n",
        "# ============================================================\n",
        "import mlflow\n",
        "from mlflow_config import init_mlflow\n",
        "from mlflow_utils import log_pytorch_model, log_label_encoder, log_training_config\n",
        "init_mlflow()\n",
        "\n",
        "# ============================================================\n",
        "# 1) Load + normalize dataframe\n",
        "# ============================================================\n",
        "CSV_PATH = \"balanced_emotion_dataset_smart.csv\"\n",
        "\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "df[\"text\"] = df[\"text\"].astype(str).str.strip().replace(r\"\\s+\", \" \", regex=True)\n",
        "\n",
        "valid_emotions = [\"joy\", \"sadness\", \"anger\", \"fear\", \"love\", \"surprise\"]\n",
        "\n",
        "def norm_label(e):\n",
        "    e = str(e).strip().lower()\n",
        "    if e in valid_emotions:\n",
        "        return e\n",
        "    if e == \"happy\":\n",
        "        return \"joy\"\n",
        "    if e in [\"mad\", \"furious\", \"rage\"]:\n",
        "        return \"anger\"\n",
        "    return None\n",
        "\n",
        "df[\"hidden_emotion_label\"] = df[\"hidden_emotion_label\"].apply(norm_label)\n",
        "df = df[df[\"hidden_emotion_label\"].notna()].reset_index(drop=True)\n",
        "\n",
        "df[\"hidden_flag_id\"] = df[\"hidden_emotion_flag\"].astype(int)\n",
        "\n",
        "le = LabelEncoder()\n",
        "df[\"emotion_id\"] = le.fit_transform(df[\"hidden_emotion_label\"])\n",
        "print(\"Label order:\", list(le.classes_))\n",
        "print(\"\\nClass distribution:\")\n",
        "print(df[\"hidden_emotion_label\"].value_counts())\n",
        "print(f\"\\nTotal samples: {len(df)}\")\n",
        "\n",
        "# Simple primary-emoji extraction\n",
        "if \"primary_emoji\" not in df.columns:\n",
        "    def first_emoji(s):\n",
        "        s = str(s)\n",
        "        for ch in s:\n",
        "            if ch in emoji.EMOJI_DATA:\n",
        "                return ch\n",
        "        return \"\"\n",
        "    df[\"primary_emoji\"] = df[\"text\"].apply(first_emoji)\n",
        "\n",
        "# ============================================================\n",
        "# 2) Train/val split with stratification\n",
        "# ============================================================\n",
        "X_train, X_val, y_train_em, y_val_em, y_train_hid, y_val_hid = train_test_split(\n",
        "    df[\"text\"],\n",
        "    df[\"emotion_id\"],\n",
        "    df[\"hidden_flag_id\"],\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df[\"emotion_id\"],\n",
        ")\n",
        "\n",
        "train_emojis = df.loc[X_train.index, \"primary_emoji\"]\n",
        "val_emojis   = df.loc[X_val.index, \"primary_emoji\"]\n",
        "\n",
        "print(f\"\\nTraining samples: {len(X_train)}\")\n",
        "print(f\"Validation samples: {len(X_val)}\")\n",
        "\n",
        "# ============================================================\n",
        "# 3) Enhanced preprocessing with text augmentation\n",
        "# ============================================================\n",
        "negative_keywords = [\n",
        "    \"hate\", \"angry\", \"mad\", \"furious\", \"sad\", \"depressed\", \"terrible\",\n",
        "    \"cry\", \"crying\", \"die\", \"dead\", \"kill\", \"killing\", \"awful\",\n",
        "    \"annoying\", \"stupid\", \"idiot\", \"worst\", \"bad\", \"horrible\"\n",
        "]\n",
        "\n",
        "positive_keywords = [\n",
        "    \"love\", \"happy\", \"joy\", \"great\", \"wonderful\", \"amazing\",\n",
        "    \"excellent\", \"perfect\", \"best\", \"good\", \"nice\", \"fantastic\"\n",
        "]\n",
        "\n",
        "def emoji_to_description(ch):\n",
        "    if not ch:\n",
        "        return \"\"\n",
        "    desc = emoji.demojize(ch).strip(\":\").replace(\"_\", \" \")\n",
        "    return desc\n",
        "\n",
        "def has_negative_word(text):\n",
        "    t = text.lower()\n",
        "    return any(neg in t for neg in negative_keywords)\n",
        "\n",
        "def has_positive_word(text):\n",
        "    t = text.lower()\n",
        "    return any(pos in t for pos in positive_keywords)\n",
        "\n",
        "def build_input(text, emoji_char):\n",
        "    \"\"\"\n",
        "    Enhanced preprocessing:\n",
        "    1) Convert emoji to semantic description\n",
        "    2) Detect emotion-text conflicts\n",
        "    3) Add context tokens\n",
        "    \"\"\"\n",
        "    text = str(text).strip()\n",
        "    desc = emoji_to_description(emoji_char)\n",
        "    token_prefixes = []\n",
        "\n",
        "    if desc:\n",
        "        token_prefixes.append(f\"[EMOJI={desc}]\")\n",
        "\n",
        "    # Enhanced conflict detection\n",
        "    if desc:\n",
        "        # Positive emojis with negative text\n",
        "        positive_emoji_cues = [\"smile\", \"grin\", \"laugh\", \"heart\", \"joy\", \"relieved\", \"wink\", \"blush\"]\n",
        "        negative_emoji_cues = [\"angry\", \"cry\", \"sad\", \"fear\", \"scared\", \"worried\", \"pouting\"]\n",
        "\n",
        "        is_positive_emoji = any(cue in desc for cue in positive_emoji_cues)\n",
        "        is_negative_emoji = any(cue in desc for cue in negative_emoji_cues)\n",
        "\n",
        "        if is_positive_emoji and has_negative_word(text):\n",
        "            token_prefixes.append(\"[CONFLICT_POS_EMOJI_NEG_TEXT]\")\n",
        "        elif is_negative_emoji and has_positive_word(text):\n",
        "            token_prefixes.append(\"[CONFLICT_NEG_EMOJI_POS_TEXT]\")\n",
        "\n",
        "        # Special handling for common emojis\n",
        "        if \"smiling\" in desc or \"grinning\" in desc:\n",
        "            token_prefixes.append(\"[SMILE_EMOJI]\")\n",
        "        elif \"heart\" in desc:\n",
        "            token_prefixes.append(\"[HEART_EMOJI]\")\n",
        "        elif \"crying\" in desc or \"tear\" in desc:\n",
        "            token_prefixes.append(\"[CRY_EMOJI]\")\n",
        "        elif \"angry\" in desc:\n",
        "            token_prefixes.append(\"[ANGRY_EMOJI]\")\n",
        "\n",
        "    # Add length indicator for hidden emotion detection\n",
        "    if len(text.split()) > 15:\n",
        "        token_prefixes.append(\"[LONG_TEXT]\")\n",
        "\n",
        "    prefix = \" \".join(token_prefixes)\n",
        "    if prefix:\n",
        "        return prefix + \" \" + text\n",
        "    return text\n",
        "\n",
        "# ============================================================\n",
        "# 4) Enhanced Dataset with text augmentation for minority classes\n",
        "# ============================================================\n",
        "model_name = \"microsoft/deberta-v3-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "print(f\"\\nTokenizer vocab size: {tokenizer.vocab_size}\")\n",
        "\n",
        "class EmotionHiddenDataset(Dataset):\n",
        "    def __init__(self, texts, emo_ids, hid_ids, emojis, augment=False):\n",
        "        self.texts = list(texts)\n",
        "        self.emo_ids = list(emo_ids)\n",
        "        self.hid_ids = list(hid_ids)\n",
        "        self.emojis = list(emojis)\n",
        "        self.augment = augment\n",
        "        self.class_distribution = Counter(emo_ids)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        raw_text = self.texts[idx]\n",
        "        emoji_char = self.emojis[idx]\n",
        "        emotion_id = self.emo_ids[idx]\n",
        "\n",
        "        # Simple text augmentation for minority classes\n",
        "        if self.augment and np.random.random() < 0.3:\n",
        "            if emotion_id in [3, 4, 5]:  # fear, love, surprise (minority classes)\n",
        "                # Add minor variations\n",
        "                variations = [\n",
        "                    f\"I feel {raw_text}\",\n",
        "                    f\"{raw_text} honestly\",\n",
        "                    f\"To be honest, {raw_text}\",\n",
        "                    f\"{raw_text} right now\"\n",
        "                ]\n",
        "                raw_text = np.random.choice(variations)\n",
        "\n",
        "        proc_text = build_input(raw_text, emoji_char)\n",
        "        return proc_text, emotion_id, self.hid_ids[idx]\n",
        "\n",
        "def collate_fn(batch):\n",
        "    texts, emo_ids, hid_ids = zip(*batch)\n",
        "    enc = tokenizer(\n",
        "        list(texts),\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=128,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "    enc[\"emotion_labels\"] = torch.tensor(emo_ids, dtype=torch.long)\n",
        "    enc[\"hidden_labels\"] = torch.tensor(hid_ids, dtype=torch.float)\n",
        "    return enc\n",
        "\n",
        "# Create datasets\n",
        "train_ds = EmotionHiddenDataset(X_train, y_train_em, y_train_hid, train_emojis, augment=True)\n",
        "val_ds = EmotionHiddenDataset(X_val, y_val_em, y_val_hid, val_emojis, augment=False)\n",
        "\n",
        "# ============================================================\n",
        "# 5) Enhanced sampling strategy\n",
        "# ============================================================\n",
        "emo_counts = Counter(y_train_em)\n",
        "print(f\"\\nTraining class counts: {dict(emo_counts)}\")\n",
        "\n",
        "# Option 1: Inverse frequency weighting\n",
        "total_samples = len(y_train_em)\n",
        "num_classes = len(emo_counts)\n",
        "beta = 0.999  # Smoothing factor for effective number of samples\n",
        "\n",
        "# Calculate effective number of samples\n",
        "effective_num = 1.0 - np.power(beta, list(emo_counts.values()))\n",
        "weights = (1.0 - beta) / np.array(effective_num)\n",
        "weights = weights / np.sum(weights) * num_classes\n",
        "class_weights = {i: float(w) for i, w in enumerate(weights)}\n",
        "\n",
        "print(\"Class weights (effective num):\", class_weights)\n",
        "\n",
        "# Create sample weights\n",
        "sample_weights = [class_weights[c] for c in y_train_em]\n",
        "sampler = WeightedRandomSampler(\n",
        "    sample_weights,\n",
        "    num_samples=len(sample_weights),\n",
        "    replacement=True\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=32,\n",
        "    sampler=sampler,\n",
        "    collate_fn=collate_fn,\n",
        "    num_workers=2 if device.type == \"cuda\" else 0\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_ds,\n",
        "    batch_size=64,\n",
        "    shuffle=False,\n",
        "    collate_fn=collate_fn,\n",
        "    num_workers=2 if device.type == \"cuda\" else 0\n",
        ")\n",
        "\n",
        "# ============================================================\n",
        "# 6) Enhanced Model Architecture\n",
        "# ============================================================\n",
        "class EnhancedEmotionHiddenModel(nn.Module):\n",
        "    def __init__(self, base_name, num_emotions, dropout_p=0.3):\n",
        "        super().__init__()\n",
        "        self.encoder = AutoModel.from_pretrained(base_name)\n",
        "        hidden_size = self.encoder.config.hidden_size\n",
        "\n",
        "        # Emotion classification head (more complex)\n",
        "        self.emotion_head = nn.Sequential(\n",
        "            nn.Linear(hidden_size, hidden_size // 2),\n",
        "            nn.LayerNorm(hidden_size // 2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout_p),\n",
        "            nn.Linear(hidden_size // 2, hidden_size // 4),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout_p),\n",
        "            nn.Linear(hidden_size // 4, num_emotions),\n",
        "        )\n",
        "\n",
        "        # Hidden flag head (simpler)\n",
        "        self.hidden_head = nn.Sequential(\n",
        "            nn.Linear(hidden_size, hidden_size // 2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout_p),\n",
        "            nn.Linear(hidden_size // 2, 1),\n",
        "        )\n",
        "\n",
        "        # Shared layers for better feature extraction\n",
        "        self.shared_projection = nn.Sequential(\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "            nn.LayerNorm(hidden_size),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout_p),\n",
        "        )\n",
        "\n",
        "        # Initialize weights\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for module in [self.emotion_head, self.hidden_head, self.shared_projection]:\n",
        "            for layer in module:\n",
        "                if isinstance(layer, nn.Linear):\n",
        "                    nn.init.xavier_uniform_(layer.weight)\n",
        "                    if layer.bias is not None:\n",
        "                        nn.init.zeros_(layer.bias)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        # Use mean pooling of all tokens (better than just CLS)\n",
        "        hidden_states = outputs.last_hidden_state\n",
        "        attention_mask_expanded = attention_mask.unsqueeze(-1).expand(hidden_states.size()).float()\n",
        "        sum_embeddings = torch.sum(hidden_states * attention_mask_expanded, dim=1)\n",
        "        sum_mask = torch.clamp(attention_mask_expanded.sum(dim=1), min=1e-9)\n",
        "        pooled = sum_embeddings / sum_mask\n",
        "\n",
        "        # Shared features\n",
        "        shared_features = self.shared_projection(pooled)\n",
        "\n",
        "        # Separate heads\n",
        "        emo_logits = self.emotion_head(shared_features)\n",
        "        hid_logits = self.hidden_head(shared_features).squeeze(-1)\n",
        "\n",
        "        return emo_logits, hid_logits\n",
        "\n",
        "num_emotions = len(le.classes_)\n",
        "model = EnhancedEmotionHiddenModel(model_name, num_emotions, dropout_p=0.3).to(device)\n",
        "print(f\"\\nModel parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "\n",
        "# ============================================================\n",
        "# 7) Enhanced Loss Functions\n",
        "# ============================================================\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=None, gamma=2.0, label_smoothing=0.1):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.label_smoothing = label_smoothing\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "        num_classes = logits.size(-1)\n",
        "\n",
        "        # Apply label smoothing\n",
        "        if self.label_smoothing > 0:\n",
        "            with torch.no_grad():\n",
        "                smooth_targets = torch.zeros_like(logits).scatter_(\n",
        "                    1, targets.unsqueeze(1), 1.0\n",
        "                )\n",
        "                smooth_targets = smooth_targets * (1 - self.label_smoothing) + self.label_smoothing / num_classes\n",
        "\n",
        "        # Calculate focal loss\n",
        "        ce_loss = F.cross_entropy(logits, targets, reduction='none')\n",
        "        pt = torch.exp(-ce_loss)\n",
        "\n",
        "        if self.label_smoothing > 0:\n",
        "            # With label smoothing\n",
        "            log_probs = F.log_softmax(logits, dim=-1)\n",
        "            ce_loss = -(smooth_targets * log_probs).sum(dim=-1)\n",
        "\n",
        "        focal_weight = (1 - pt) ** self.gamma\n",
        "\n",
        "        if self.alpha is not None:\n",
        "            alpha_weight = self.alpha[targets]\n",
        "            focal_weight = focal_weight * alpha_weight\n",
        "\n",
        "        loss = focal_weight * ce_loss\n",
        "        return loss.mean()\n",
        "\n",
        "class EnhancedMultitaskLoss(nn.Module):\n",
        "    def __init__(self, class_weights_dict, gamma=2.0, hidden_weight=1.0):\n",
        "        super().__init__()\n",
        "        # Convert class weights to tensor\n",
        "        alpha_tensor = torch.zeros(len(class_weights_dict))\n",
        "        for idx, weight in class_weights_dict.items():\n",
        "            alpha_tensor[idx] = weight\n",
        "\n",
        "        # Normalize alpha\n",
        "        alpha_tensor = alpha_tensor / alpha_tensor.sum() * len(alpha_tensor)\n",
        "\n",
        "        self.emo_loss = FocalLoss(\n",
        "            alpha=alpha_tensor.to(device),\n",
        "            gamma=gamma,\n",
        "            label_smoothing=0.1\n",
        "        )\n",
        "        self.hid_loss = nn.BCEWithLogitsLoss(\n",
        "            pos_weight=torch.tensor([2.0]).to(device)  # Adjust based on hidden flag ratio\n",
        "        )\n",
        "        self.hidden_weight = hidden_weight\n",
        "\n",
        "    def forward(self, emo_logits, emo_targets, hid_logits, hid_targets):\n",
        "        l_emo = self.emo_loss(emo_logits, emo_targets)\n",
        "        l_hid = self.hid_loss(hid_logits, hid_targets)\n",
        "        total_loss = l_emo + self.hidden_weight * l_hid\n",
        "        return total_loss, l_emo, l_hid\n",
        "\n",
        "# Create loss function with class weights\n",
        "criterion = EnhancedMultitaskLoss(\n",
        "    class_weights_dict=class_weights,\n",
        "    gamma=1.5,  # Lower gamma for less aggressive focal loss\n",
        "    hidden_weight=0.8  # Start with lower weight for hidden task\n",
        ")\n",
        "\n",
        "# ============================================================\n",
        "# 8) Enhanced Optimizer and Scheduler\n",
        "# ============================================================\n",
        "# Freeze first few layers of encoder\n",
        "for name, param in model.named_parameters():\n",
        "    if \"encoder.embeddings\" in name or \"encoder.encoder.layer.0\" in name or \"encoder.encoder.layer.1\" in name:\n",
        "        param.requires_grad = False\n",
        "\n",
        "# Group parameters\n",
        "encoder_params = []\n",
        "head_params = []\n",
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        if \"encoder\" in name:\n",
        "            encoder_params.append(param)\n",
        "        else:\n",
        "            head_params.append(param)\n",
        "\n",
        "print(f\"\\nTrainable encoder params: {len(encoder_params)}\")\n",
        "print(f\"Trainable head params: {len(head_params)}\")\n",
        "\n",
        "optimizer = torch.optim.AdamW(\n",
        "    [\n",
        "        {\"params\": encoder_params, \"lr\": 2e-5, \"weight_decay\": 0.01},\n",
        "        {\"params\": head_params, \"lr\": 5e-5, \"weight_decay\": 0.01},\n",
        "    ],\n",
        "    eps=1e-8,\n",
        "    betas=(0.9, 0.999)\n",
        ")\n",
        "\n",
        "# Linear warmup + cosine annealing\n",
        "num_epochs = 5\n",
        "num_training_steps = num_epochs * len(train_loader)\n",
        "num_warmup_steps = int(0.1 * num_training_steps)\n",
        "\n",
        "scheduler = get_cosine_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=num_warmup_steps,\n",
        "    num_training_steps=num_training_steps,\n",
        ")\n",
        "\n",
        "# ============================================================\n",
        "# 9) Enhanced Evaluation with per-class metrics\n",
        "# ============================================================\n",
        "def evaluate_model(model, loader, criterion=None):\n",
        "    model.eval()\n",
        "    all_true_emo, all_pred_emo = [], []\n",
        "    all_true_hid, all_pred_hid = [], []\n",
        "    all_emo_probs = []\n",
        "\n",
        "    total_loss = 0\n",
        "    num_batches = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            batch = {\n",
        "                k: v.to(device) if isinstance(v, torch.Tensor) else v\n",
        "                for k, v in batch.items()\n",
        "            }\n",
        "\n",
        "            emo_logits, hid_logits = model(\n",
        "                input_ids=batch[\"input_ids\"],\n",
        "                attention_mask=batch[\"attention_mask\"],\n",
        "            )\n",
        "\n",
        "            if criterion is not None:\n",
        "                loss, l_emo, l_hid = criterion(\n",
        "                    emo_logits,\n",
        "                    batch[\"emotion_labels\"],\n",
        "                    hid_logits,\n",
        "                    batch[\"hidden_labels\"],\n",
        "                )\n",
        "                total_loss += loss.item()\n",
        "                num_batches += 1\n",
        "\n",
        "            # Emotion predictions\n",
        "            emo_probs = torch.softmax(emo_logits, dim=-1)\n",
        "            emo_preds = emo_logits.argmax(dim=-1)\n",
        "\n",
        "            # Hidden predictions\n",
        "            hid_probs = torch.sigmoid(hid_logits)\n",
        "            hid_preds = (hid_probs > 0.5).long()\n",
        "\n",
        "            all_true_emo.extend(batch[\"emotion_labels\"].cpu().numpy())\n",
        "            all_pred_emo.extend(emo_preds.cpu().numpy())\n",
        "            all_true_hid.extend(batch[\"hidden_labels\"].cpu().numpy())\n",
        "            all_pred_hid.extend(hid_preds.cpu().numpy())\n",
        "            all_emo_probs.extend(emo_probs.cpu().numpy())\n",
        "\n",
        "    # Calculate metrics\n",
        "    print(\"=\" * 60)\n",
        "    print(\"EMOTION CLASSIFICATION REPORT\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Full classification report\n",
        "    print(classification_report(\n",
        "        all_true_emo,\n",
        "        all_pred_emo,\n",
        "        target_names=le.classes_,\n",
        "        digits=3,\n",
        "        zero_division=0\n",
        "    ))\n",
        "\n",
        "    # Per-class accuracy\n",
        "    print(\"\\nPER-CLASS ACCURACY:\")\n",
        "    cm = confusion_matrix(all_true_emo, all_pred_emo)\n",
        "    for i, emotion in enumerate(le.classes_):\n",
        "        total = cm[i].sum()\n",
        "        correct = cm[i, i]\n",
        "        acc = correct / total if total > 0 else 0\n",
        "        print(f\"{emotion:10s}: {acc:.3f} ({correct}/{total})\")\n",
        "\n",
        "    # Macro and weighted averages\n",
        "    macro_acc = accuracy_score(all_true_emo, all_pred_emo)\n",
        "    print(f\"\\nOverall Accuracy: {macro_acc:.3f}\")\n",
        "\n",
        "    # Hidden flag metrics\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"HIDDEN FLAG DETECTION\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    acc_hid = accuracy_score(all_true_hid, all_pred_hid)\n",
        "    prec_hid, rec_hid, f1_hid, _ = precision_recall_fscore_support(\n",
        "        all_true_hid,\n",
        "        all_pred_hid,\n",
        "        average=\"binary\",\n",
        "        pos_label=1,\n",
        "        zero_division=0\n",
        "    )\n",
        "\n",
        "    print(f\"Accuracy:  {acc_hid:.3f}\")\n",
        "    print(f\"Precision: {prec_hid:.3f}\")\n",
        "    print(f\"Recall:    {rec_hid:.3f}\")\n",
        "    print(f\"F1-Score:  {f1_hid:.3f}\")\n",
        "\n",
        "    # Confusion matrix for hidden flag\n",
        "    cm_hid = confusion_matrix(all_true_hid, all_pred_hid)\n",
        "    print(f\"\\nConfusion Matrix (Hidden Flag):\")\n",
        "    print(cm_hid)\n",
        "\n",
        "    if criterion is not None:\n",
        "        avg_loss = total_loss / max(num_batches, 1)\n",
        "        print(f\"\\nValidation Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    return {\n",
        "        \"emo_accuracy\": macro_acc,\n",
        "        \"hid_accuracy\": acc_hid,\n",
        "        \"hid_f1\": f1_hid,\n",
        "        \"emo_probs\": all_emo_probs,\n",
        "        \"predictions\": all_pred_emo\n",
        "    }\n",
        "\n",
        "# ============================================================\n",
        "# 10) Enhanced Training Loop with early stopping\n",
        "# ============================================================\n",
        "def train_model():\n",
        "    best_val_acc = 0\n",
        "    patience = 3\n",
        "    patience_counter = 0\n",
        "    best_model_state = None\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"STARTING TRAINING\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\n{'='*40}\")\n",
        "        print(f\"EPOCH {epoch + 1}/{num_epochs}\")\n",
        "        print(f\"{'='*40}\")\n",
        "\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        emo_correct = 0\n",
        "        hid_correct = 0\n",
        "        total_samples = 0\n",
        "\n",
        "        for batch_idx, batch in enumerate(train_loader):\n",
        "            batch = {\n",
        "                k: v.to(device) if isinstance(v, torch.Tensor) else v\n",
        "                for k, v in batch.items()\n",
        "            }\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            emo_logits, hid_logits = model(\n",
        "                input_ids=batch[\"input_ids\"],\n",
        "                attention_mask=batch[\"attention_mask\"],\n",
        "            )\n",
        "\n",
        "            loss, l_emo, l_hid = criterion(\n",
        "                emo_logits,\n",
        "                batch[\"emotion_labels\"],\n",
        "                hid_logits,\n",
        "                batch[\"hidden_labels\"],\n",
        "            )\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            # Gradient clipping\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            # Calculate batch accuracy\n",
        "            emo_preds = emo_logits.argmax(dim=-1)\n",
        "            hid_preds = (torch.sigmoid(hid_logits) > 0.5).long()\n",
        "\n",
        "            emo_correct += (emo_preds == batch[\"emotion_labels\"]).sum().item()\n",
        "            hid_correct += (hid_preds == batch[\"hidden_labels\"].long()).sum().item()\n",
        "            total_samples += len(batch[\"emotion_labels\"])\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            if (batch_idx + 1) % 50 == 0:\n",
        "                print(f\"  Batch {batch_idx + 1}/{len(train_loader)} | \"\n",
        "                      f\"Loss: {loss.item():.4f} | \"\n",
        "                      f\"Emo Acc: {emo_correct/total_samples:.3f} | \"\n",
        "                      f\"Hid Acc: {hid_correct/total_samples:.3f}\")\n",
        "\n",
        "        avg_train_loss = train_loss / len(train_loader)\n",
        "        train_emo_acc = emo_correct / total_samples\n",
        "        train_hid_acc = hid_correct / total_samples\n",
        "\n",
        "        print(f\"\\nTraining Summary:\")\n",
        "        print(f\"  Avg Loss: {avg_train_loss:.4f}\")\n",
        "        print(f\"  Emotion Accuracy: {train_emo_acc:.3f}\")\n",
        "        print(f\"  Hidden Accuracy: {train_hid_acc:.3f}\")\n",
        "        if mlflow.active_run():\n",
        "            mlflow.log_metrics({\"train_loss\": avg_train_loss, \"train_emo_accuracy\": train_emo_acc, \"train_hid_accuracy\": train_hid_acc}, step=epoch + 1)\n",
        "\n",
        "        # Validation phase\n",
        "        print(f\"\\nValidation Results:\")\n",
        "        val_metrics = evaluate_model(model, val_loader, criterion)\n",
        "        if mlflow.active_run():\n",
        "            mlflow.log_metrics({\"val_emo_accuracy\": val_metrics[\"emo_accuracy\"], \"val_hid_accuracy\": val_metrics[\"hid_accuracy\"], \"val_hid_f1\": val_metrics[\"hid_f1\"]}, step=epoch + 1)\n",
        "\n",
        "        # Early stopping check\n",
        "        current_val_acc = val_metrics[\"emo_accuracy\"]\n",
        "\n",
        "        if current_val_acc > best_val_acc:\n",
        "            best_val_acc = current_val_acc\n",
        "            patience_counter = 0\n",
        "            best_model_state = model.state_dict().copy()\n",
        "            torch.save(model.state_dict(), \"best_emotion_model.pt\")\n",
        "            print(f\"  ✓ New best model saved! (Acc: {current_val_acc:.3f})\")\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            print(f\"  ⏳ No improvement ({patience_counter}/{patience})\")\n",
        "\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"\\nEarly stopping triggered at epoch {epoch + 1}\")\n",
        "            break\n",
        "\n",
        "    # Load best model\n",
        "    if best_model_state is not None:\n",
        "        model.load_state_dict(best_model_state)\n",
        "        print(f\"\\nLoaded best model with validation accuracy: {best_val_acc:.3f}\")\n",
        "\n",
        "    # Final evaluation\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"FINAL EVALUATION ON BEST MODEL\")\n",
        "    print(\"=\" * 60)\n",
        "    final_metrics = evaluate_model(model, val_loader)\n",
        "\n",
        "    return model, final_metrics\n",
        "\n",
        "# ============================================================\n",
        "# 11) Train the model (with MLflow)\n",
        "# ============================================================\n",
        "with mlflow.start_run():\n",
        "    mlflow.log_params({\n",
        "        \"model_name\": model_name,\n",
        "        \"num_epochs\": num_epochs,\n",
        "        \"batch_size\": 32,\n",
        "        \"lr_encoder\": 2e-5,\n",
        "        \"lr_head\": 5e-5,\n",
        "        \"data\": CSV_PATH,\n",
        "        \"max_length\": 128,\n",
        "    })\n",
        "    trained_model, metrics = train_model()\n",
        "    mlflow.log_metrics({\n",
        "        \"final_val_emo_accuracy\": metrics[\"emo_accuracy\"],\n",
        "        \"final_val_hid_accuracy\": metrics[\"hid_accuracy\"],\n",
        "        \"final_val_hid_f1\": metrics[\"hid_f1\"],\n",
        "    })\n",
        "    log_pytorch_model(trained_model, artifact_path=\"model\")\n",
        "    log_label_encoder(le)\n",
        "    log_training_config({\"class_names\": list(le.classes_)})\n",
        "\n",
        "# Save locally as well\n",
        "torch.save({\n",
        "    'model_state_dict': trained_model.state_dict(),\n",
        "    'label_encoder': le,\n",
        "    'class_names': list(le.classes_),\n",
        "    'tokenizer': tokenizer,\n",
        "}, \"final_emotion_hidden_model.pt\")\n",
        "\n",
        "print(\"\\nModel saved as 'final_emotion_hidden_model.pt'\")\n",
        "\n",
        "# ============================================================\n",
        "# 12) Prediction function\n",
        "# ============================================================\n",
        "def predict_emotion(text, emoji_char=\"\", model=None, tokenizer=None, le=None):\n",
        "    if model is None:\n",
        "        # Load saved model\n",
        "        checkpoint = torch.load(\"final_emotion_hidden_model.pt\", map_location=device)\n",
        "        model = EnhancedEmotionHiddenModel(model_name, len(checkpoint['class_names'])).to(device)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        le = checkpoint['label_encoder']\n",
        "        tokenizer = checkpoint['tokenizer']\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Preprocess\n",
        "    proc_text = build_input(text, emoji_char)\n",
        "\n",
        "    # Tokenize\n",
        "    enc = tokenizer(\n",
        "        proc_text,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=128,\n",
        "        return_tensors=\"pt\",\n",
        "    ).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        emo_logits, hid_logits = model(\n",
        "            input_ids=enc[\"input_ids\"],\n",
        "            attention_mask=enc[\"attention_mask\"],\n",
        "        )\n",
        "\n",
        "        emo_probs = torch.softmax(emo_logits, dim=-1)[0]\n",
        "        hid_prob = torch.sigmoid(hid_logits)[0].item()\n",
        "\n",
        "        emo_id = torch.argmax(emo_probs).item()\n",
        "        emo_label = le.inverse_transform([emo_id])[0]\n",
        "        emo_confidence = emo_probs[emo_id].item()\n",
        "\n",
        "        # Get top-3 predictions\n",
        "        top_probs, top_indices = torch.topk(emo_probs, 3)\n",
        "        top_emotions = le.inverse_transform(top_indices.cpu().numpy())\n",
        "        top_confidences = top_probs.cpu().numpy()\n",
        "\n",
        "    result = {\n",
        "        \"predicted_emotion\": emo_label,\n",
        "        \"emotion_confidence\": emo_confidence,\n",
        "        \"hidden_probability\": hid_prob,\n",
        "        \"is_hidden\": hid_prob > 0.5,\n",
        "        \"top_predictions\": [\n",
        "            {\"emotion\": e, \"confidence\": float(c)}\n",
        "            for e, c in zip(top_emotions, top_confidences)\n",
        "        ],\n",
        "        \"processed_text\": proc_text\n",
        "    }\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Label order: ['anger', 'fear', 'joy', 'love', 'sadness', 'surprise']\n",
            "\n",
            "Class distribution:\n",
            "hidden_emotion_label\n",
            "anger       1195\n",
            "joy         1065\n",
            "sadness     1032\n",
            "fear         439\n",
            "love         363\n",
            "surprise     339\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Total samples: 4433\n",
            "\n",
            "Training samples: 3546\n",
            "Validation samples: 887\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f09525107b50474ab191fb3bf47b2353",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
            ]
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4890a92d817a4c0e9fe4bf5f4018c017",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]"
            ]
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "92013bba4f0f4c5fb691abb492605567",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
            ]
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Tokenizer vocab size: 128000\n",
            "\n",
            "Training class counts: {2: 852, 4: 826, 3: 290, 5: 271, 0: 956, 1: 351}\n",
            "Class weights (effective num): {0: 0.6262003418440383, 1: 0.6387123742438989, 2: 1.4262803458788826, 3: 1.5125110761714946, 4: 0.5833502001023915, 5: 1.212945661759293}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "20154019142340fa808961e59c3efdbc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/371M [00:00<?, ?B/s]"
            ]
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Model parameters: 185,090,503\n",
            "\n",
            "Trainable encoder params: 131\n",
            "Trainable head params: 16\n",
            "\n",
            "============================================================\n",
            "STARTING TRAINING\n",
            "============================================================\n",
            "\n",
            "========================================\n",
            "EPOCH 1/5\n",
            "========================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "94663506177040609a08c874cae771c9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/371M [00:00<?, ?B/s]"
            ]
          }
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 50/111 | Loss: 2.1392 | Emo Acc: 0.259 | Hid Acc: 0.466\n",
            "  Batch 100/111 | Loss: 1.5656 | Emo Acc: 0.332 | Hid Acc: 0.481\n",
            "\n",
            "Training Summary:\n",
            "  Avg Loss: 2.1303\n",
            "  Emotion Accuracy: 0.350\n",
            "  Hidden Accuracy: 0.488\n",
            "\n",
            "Validation Results:\n",
            "============================================================\n",
            "EMOTION CLASSIFICATION REPORT\n",
            "============================================================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger      0.000     0.000     0.000       239\n",
            "        fear      0.000     0.000     0.000        88\n",
            "         joy      0.360     0.981     0.527       213\n",
            "        love      0.631     0.726     0.675        73\n",
            "     sadness      0.667     0.049     0.090       206\n",
            "    surprise      0.271     0.824     0.407        68\n",
            "\n",
            "    accuracy                          0.370       887\n",
            "   macro avg      0.321     0.430     0.283       887\n",
            "weighted avg      0.314     0.370     0.234       887\n",
            "\n",
            "\n",
            "PER-CLASS ACCURACY:\n",
            "anger     : 0.000 (0/239)\n",
            "fear      : 0.000 (0/88)\n",
            "joy       : 0.981 (209/213)\n",
            "love      : 0.726 (53/73)\n",
            "sadness   : 0.049 (10/206)\n",
            "surprise  : 0.824 (56/68)\n",
            "\n",
            "Overall Accuracy: 0.370\n",
            "\n",
            "============================================================\n",
            "HIDDEN FLAG DETECTION\n",
            "============================================================\n",
            "Accuracy:  0.611\n",
            "Precision: 0.588\n",
            "Recall:    0.885\n",
            "F1-Score:  0.706\n",
            "\n",
            "Confusion Matrix (Hidden Flag):\n",
            "[[127 291]\n",
            " [ 54 415]]\n",
            "\n",
            "Validation Loss: 1.5811\n",
            "  ✓ New best model saved! (Acc: 0.370)\n",
            "\n",
            "========================================\n",
            "EPOCH 2/5\n",
            "========================================\n",
            "  Batch 50/111 | Loss: 0.9588 | Emo Acc: 0.578 | Hid Acc: 0.660\n",
            "  Batch 100/111 | Loss: 0.9841 | Emo Acc: 0.606 | Hid Acc: 0.685\n",
            "\n",
            "Training Summary:\n",
            "  Avg Loss: 1.2297\n",
            "  Emotion Accuracy: 0.613\n",
            "  Hidden Accuracy: 0.688\n",
            "\n",
            "Validation Results:\n",
            "============================================================\n",
            "EMOTION CLASSIFICATION REPORT\n",
            "============================================================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger      0.390     0.238     0.296       239\n",
            "        fear      0.454     0.670     0.541        88\n",
            "         joy      0.467     0.939     0.624       213\n",
            "        love      0.810     0.877     0.842        73\n",
            "     sadness      0.909     0.097     0.175       206\n",
            "    surprise      0.768     0.926     0.840        68\n",
            "\n",
            "    accuracy                          0.522       887\n",
            "   macro avg      0.633     0.625     0.553       887\n",
            "weighted avg      0.599     0.522     0.458       887\n",
            "\n",
            "\n",
            "PER-CLASS ACCURACY:\n",
            "anger     : 0.238 (57/239)\n",
            "fear      : 0.670 (59/88)\n",
            "joy       : 0.939 (200/213)\n",
            "love      : 0.877 (64/73)\n",
            "sadness   : 0.097 (20/206)\n",
            "surprise  : 0.926 (63/68)\n",
            "\n",
            "Overall Accuracy: 0.522\n",
            "\n",
            "============================================================\n",
            "HIDDEN FLAG DETECTION\n",
            "============================================================\n",
            "Accuracy:  0.726\n",
            "Precision: 0.773\n",
            "Recall:    0.682\n",
            "F1-Score:  0.725\n",
            "\n",
            "Confusion Matrix (Hidden Flag):\n",
            "[[324  94]\n",
            " [149 320]]\n",
            "\n",
            "Validation Loss: 1.1898\n",
            "  ✓ New best model saved! (Acc: 0.522)\n",
            "\n",
            "========================================\n",
            "EPOCH 3/5\n",
            "========================================\n",
            "  Batch 50/111 | Loss: 0.8145 | Emo Acc: 0.693 | Hid Acc: 0.777\n",
            "  Batch 100/111 | Loss: 0.8237 | Emo Acc: 0.725 | Hid Acc: 0.795\n",
            "\n",
            "Training Summary:\n",
            "  Avg Loss: 0.8406\n",
            "  Emotion Accuracy: 0.729\n",
            "  Hidden Accuracy: 0.801\n",
            "\n",
            "Validation Results:\n",
            "============================================================\n",
            "EMOTION CLASSIFICATION REPORT\n",
            "============================================================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger      0.663     0.527     0.587       239\n",
            "        fear      0.937     0.841     0.886        88\n",
            "         joy      0.539     0.911     0.677       213\n",
            "        love      0.802     0.890     0.844        73\n",
            "     sadness      0.850     0.442     0.581       206\n",
            "    surprise      0.914     0.941     0.928        68\n",
            "\n",
            "    accuracy                          0.692       887\n",
            "   macro avg      0.784     0.759     0.751       887\n",
            "weighted avg      0.735     0.692     0.684       887\n",
            "\n",
            "\n",
            "PER-CLASS ACCURACY:\n",
            "anger     : 0.527 (126/239)\n",
            "fear      : 0.841 (74/88)\n",
            "joy       : 0.911 (194/213)\n",
            "love      : 0.890 (65/73)\n",
            "sadness   : 0.442 (91/206)\n",
            "surprise  : 0.941 (64/68)\n",
            "\n",
            "Overall Accuracy: 0.692\n",
            "\n",
            "============================================================\n",
            "HIDDEN FLAG DETECTION\n",
            "============================================================\n",
            "Accuracy:  0.799\n",
            "Precision: 0.813\n",
            "Recall:    0.806\n",
            "F1-Score:  0.809\n",
            "\n",
            "Confusion Matrix (Hidden Flag):\n",
            "[[331  87]\n",
            " [ 91 378]]\n",
            "\n",
            "Validation Loss: 0.9813\n",
            "  ✓ New best model saved! (Acc: 0.692)\n",
            "\n",
            "========================================\n",
            "EPOCH 4/5\n",
            "========================================\n",
            "  Batch 50/111 | Loss: 0.5129 | Emo Acc: 0.770 | Hid Acc: 0.848\n",
            "  Batch 100/111 | Loss: 0.6094 | Emo Acc: 0.785 | Hid Acc: 0.864\n",
            "\n",
            "Training Summary:\n",
            "  Avg Loss: 0.6422\n",
            "  Emotion Accuracy: 0.788\n",
            "  Hidden Accuracy: 0.865\n",
            "\n",
            "Validation Results:\n",
            "============================================================\n",
            "EMOTION CLASSIFICATION REPORT\n",
            "============================================================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger      0.737     0.527     0.615       239\n",
            "        fear      0.964     0.909     0.936        88\n",
            "         joy      0.549     0.944     0.694       213\n",
            "        love      0.900     0.863     0.881        73\n",
            "     sadness      0.836     0.519     0.641       206\n",
            "    surprise      0.942     0.956     0.949        68\n",
            "\n",
            "    accuracy                          0.724       887\n",
            "   macro avg      0.821     0.786     0.786       887\n",
            "weighted avg      0.766     0.724     0.719       887\n",
            "\n",
            "\n",
            "PER-CLASS ACCURACY:\n",
            "anger     : 0.527 (126/239)\n",
            "fear      : 0.909 (80/88)\n",
            "joy       : 0.944 (201/213)\n",
            "love      : 0.863 (63/73)\n",
            "sadness   : 0.519 (107/206)\n",
            "surprise  : 0.956 (65/68)\n",
            "\n",
            "Overall Accuracy: 0.724\n",
            "\n",
            "============================================================\n",
            "HIDDEN FLAG DETECTION\n",
            "============================================================\n",
            "Accuracy:  0.839\n",
            "Precision: 0.837\n",
            "Recall:    0.864\n",
            "F1-Score:  0.850\n",
            "\n",
            "Confusion Matrix (Hidden Flag):\n",
            "[[339  79]\n",
            " [ 64 405]]\n",
            "\n",
            "Validation Loss: 0.8352\n",
            "  ✓ New best model saved! (Acc: 0.724)\n",
            "\n",
            "========================================\n",
            "EPOCH 5/5\n",
            "========================================\n",
            "  Batch 50/111 | Loss: 0.4710 | Emo Acc: 0.787 | Hid Acc: 0.879\n",
            "  Batch 100/111 | Loss: 0.5913 | Emo Acc: 0.792 | Hid Acc: 0.880\n",
            "\n",
            "Training Summary:\n",
            "  Avg Loss: 0.5912\n",
            "  Emotion Accuracy: 0.795\n",
            "  Hidden Accuracy: 0.882\n",
            "\n",
            "Validation Results:\n",
            "============================================================\n",
            "EMOTION CLASSIFICATION REPORT\n",
            "============================================================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger      0.662     0.632     0.647       239\n",
            "        fear      0.941     0.909     0.925        88\n",
            "         joy      0.593     0.925     0.723       213\n",
            "        love      0.878     0.890     0.884        73\n",
            "     sadness      0.865     0.437     0.581       206\n",
            "    surprise      0.984     0.926     0.955        68\n",
            "\n",
            "    accuracy                          0.728       887\n",
            "   macro avg      0.821     0.787     0.786       887\n",
            "weighted avg      0.763     0.728     0.720       887\n",
            "\n",
            "\n",
            "PER-CLASS ACCURACY:\n",
            "anger     : 0.632 (151/239)\n",
            "fear      : 0.909 (80/88)\n",
            "joy       : 0.925 (197/213)\n",
            "love      : 0.890 (65/73)\n",
            "sadness   : 0.437 (90/206)\n",
            "surprise  : 0.926 (63/68)\n",
            "\n",
            "Overall Accuracy: 0.728\n",
            "\n",
            "============================================================\n",
            "HIDDEN FLAG DETECTION\n",
            "============================================================\n",
            "Accuracy:  0.852\n",
            "Precision: 0.848\n",
            "Recall:    0.878\n",
            "F1-Score:  0.863\n",
            "\n",
            "Confusion Matrix (Hidden Flag):\n",
            "[[344  74]\n",
            " [ 57 412]]\n",
            "\n",
            "Validation Loss: 0.7940\n",
            "  ✓ New best model saved! (Acc: 0.728)\n",
            "\n",
            "Loaded best model with validation accuracy: 0.728\n",
            "\n",
            "============================================================\n",
            "FINAL EVALUATION ON BEST MODEL\n",
            "============================================================\n",
            "============================================================\n",
            "EMOTION CLASSIFICATION REPORT\n",
            "============================================================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger      0.662     0.632     0.647       239\n",
            "        fear      0.941     0.909     0.925        88\n",
            "         joy      0.593     0.925     0.723       213\n",
            "        love      0.878     0.890     0.884        73\n",
            "     sadness      0.865     0.437     0.581       206\n",
            "    surprise      0.984     0.926     0.955        68\n",
            "\n",
            "    accuracy                          0.728       887\n",
            "   macro avg      0.821     0.787     0.786       887\n",
            "weighted avg      0.763     0.728     0.720       887\n",
            "\n",
            "\n",
            "PER-CLASS ACCURACY:\n",
            "anger     : 0.632 (151/239)\n",
            "fear      : 0.909 (80/88)\n",
            "joy       : 0.925 (197/213)\n",
            "love      : 0.890 (65/73)\n",
            "sadness   : 0.437 (90/206)\n",
            "surprise  : 0.926 (63/68)\n",
            "\n",
            "Overall Accuracy: 0.728\n",
            "\n",
            "============================================================\n",
            "HIDDEN FLAG DETECTION\n",
            "============================================================\n",
            "Accuracy:  0.852\n",
            "Precision: 0.848\n",
            "Recall:    0.878\n",
            "F1-Score:  0.863\n",
            "\n",
            "Confusion Matrix (Hidden Flag):\n",
            "[[344  74]\n",
            " [ 57 412]]\n",
            "\n",
            "Model saved as 'final_emotion_hidden_model.pt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqMFckn6i2v-",
        "outputId": "10a21aae-6e60-4f3f-a5dc-a7213d249d3f"
      },
      "source": [
        "drive_path = \"model\"  # folder (relative path in workspace)\n",
        "\n",
        "import os, torch, pickle, json\n",
        "os.makedirs(drive_path, exist_ok=True)\n",
        "\n",
        "\n",
        "\n",
        "# 1) save tokenizer\n",
        "tokenizer.save_pretrained(drive_path)\n",
        "\n",
        "# 2) save label encoder + class names\n",
        "with open(f\"{drive_path}/label_encoder.pkl\", \"wb\") as f:\n",
        "    pickle.dump(le, f)\n",
        "\n",
        "class_names = list(le.classes_)\n",
        "with open(f\"{drive_path}/class_names.json\", \"w\") as f:\n",
        "    json.dump(class_names, f)\n",
        "\n",
        "# 3) save model weights\n",
        "torch.save(trained_model.state_dict(), f\"{drive_path}/model_state.pt\")\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'tokenizer' is not defined",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m os.makedirs(drive_path, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# 1) save tokenizer\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mtokenizer\u001b[49m.save_pretrained(drive_path)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# 2) save label encoder + class names\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdrive_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/label_encoder.pkl\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
            "\u001b[31mNameError\u001b[39m: name 'tokenizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjN2l3_WjWzd",
        "outputId": "dd59d314-cb9a-485d-bc73-ba3858371152"
      },
      "source": [
        "import torch, pickle, json\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import emoji\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "drive_path = \"model\"  # relative path in workspace\n",
        "model_name = \"microsoft/deberta-v3-base\"\n",
        "\n",
        "# tokenizer + labels\n",
        "tokenizer = AutoTokenizer.from_pretrained(drive_path)\n",
        "with open(f\"{drive_path}/label_encoder.pkl\", \"rb\") as f:\n",
        "    le = pickle.load(f)\n",
        "with open(f\"{drive_path}/class_names.json\", \"r\") as f:\n",
        "    class_names = json.load(f)\n",
        "\n",
        "# SAME build_input as in training\n",
        "negative_keywords = [\n",
        "    \"hate\", \"angry\", \"mad\", \"furious\", \"sad\", \"depressed\", \"terrible\",\n",
        "    \"cry\", \"crying\", \"die\", \"dead\", \"kill\", \"killing\", \"awful\",\n",
        "    \"annoying\", \"stupid\", \"idiot\", \"worst\", \"bad\", \"horrible\"\n",
        "]\n",
        "\n",
        "positive_keywords = [\n",
        "    \"love\", \"happy\", \"joy\", \"great\", \"wonderful\", \"amazing\",\n",
        "    \"excellent\", \"perfect\", \"best\", \"good\", \"nice\", \"fantastic\"\n",
        "]\n",
        "\n",
        "def emoji_to_description(ch):\n",
        "    if not ch:\n",
        "        return \"\"\n",
        "    desc = emoji.demojize(ch).strip(\":\").replace(\"_\", \" \")\n",
        "    return desc\n",
        "\n",
        "def has_negative_word(text):\n",
        "    t = text.lower()\n",
        "    return any(neg in t for neg in negative_keywords)\n",
        "\n",
        "def has_positive_word(text):\n",
        "    t = text.lower()\n",
        "    return any(pos in t for pos in positive_keywords)\n",
        "\n",
        "def build_input(text, emoji_char):\n",
        "    \"\"\"\n",
        "    Enhanced preprocessing:\n",
        "    1) Convert emoji to semantic description\n",
        "    2) Detect emotion-text conflicts\n",
        "    3) Add context tokens\n",
        "    \"\"\"\n",
        "    text = str(text).strip()\n",
        "    desc = emoji_to_description(emoji_char)\n",
        "    token_prefixes = []\n",
        "\n",
        "    if desc:\n",
        "        token_prefixes.append(f\"[EMOJI={desc}]\")\n",
        "\n",
        "    # Enhanced conflict detection\n",
        "    if desc:\n",
        "        # Positive emojis with negative text\n",
        "        positive_emoji_cues = [\"smile\", \"grin\", \"laugh\", \"heart\", \"joy\", \"relieved\", \"wink\", \"blush\"]\n",
        "        negative_emoji_cues = [\"angry\", \"cry\", \"sad\", \"fear\", \"scared\", \"worried\", \"pouting\"]\n",
        "\n",
        "        is_positive_emoji = any(cue in desc for cue in positive_emoji_cues)\n",
        "        is_negative_emoji = any(cue in desc for cue in negative_emoji_cues)\n",
        "\n",
        "        if is_positive_emoji and has_negative_word(text):\n",
        "            token_prefixes.append(\"[CONFLICT_POS_EMOJI_NEG_TEXT]\")\n",
        "        elif is_negative_emoji and has_positive_word(text):\n",
        "            token_prefixes.append(\"[CONFLICT_NEG_EMOJI_POS_TEXT]\")\n",
        "\n",
        "        # Special handling for common emojis\n",
        "        if \"smiling\" in desc or \"grinning\" in desc:\n",
        "            token_prefixes.append(\"[SMILE_EMOJI]\")\n",
        "        elif \"heart\" in desc:\n",
        "            token_prefixes.append(\"[HEART_EMOJI]\")\n",
        "        elif \"crying\" in desc or \"tear\" in desc:\n",
        "            token_prefixes.append(\"[CRY_EMOJI]\")\n",
        "        elif \"angry\" in desc:\n",
        "            token_prefixes.append(\"[ANGRY_EMOJI]\")\n",
        "\n",
        "    # Add length indicator for hidden emotion detection\n",
        "    if len(text.split()) > 15:\n",
        "        token_prefixes.append(\"[LONG_TEXT]\")\n",
        "\n",
        "    prefix = \" \".join(token_prefixes)\n",
        "    if prefix:\n",
        "        return prefix + \" \" + text\n",
        "    return text\n",
        "\n",
        "class EnhancedEmotionHiddenModel(nn.Module):\n",
        "    def __init__(self, base_name, num_emotions, dropout_p=0.3):\n",
        "        super().__init__()\n",
        "        self.encoder = AutoModel.from_pretrained(base_name)\n",
        "        hidden_size = self.encoder.config.hidden_size\n",
        "        self.emotion_head = nn.Sequential(\n",
        "            nn.Linear(hidden_size, hidden_size // 2),\n",
        "            nn.LayerNorm(hidden_size // 2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout_p),\n",
        "            nn.Linear(hidden_size // 2, hidden_size // 4),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout_p),\n",
        "            nn.Linear(hidden_size // 4, num_emotions),\n",
        "        )\n",
        "        self.hidden_head = nn.Sequential(\n",
        "            nn.Linear(hidden_size, hidden_size // 2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout_p),\n",
        "            nn.Linear(hidden_size // 2, 1),\n",
        "        )\n",
        "        self.shared_projection = nn.Sequential(\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "            nn.LayerNorm(hidden_size),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout_p),\n",
        "        )\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        hs = outputs.last_hidden_state\n",
        "        mask_exp = attention_mask.unsqueeze(-1).expand(hs.size()).float()\n",
        "        summed = (hs * mask_exp).sum(dim=1)\n",
        "        summed_mask = torch.clamp(mask_exp.sum(dim=1), min=1e-9)\n",
        "        pooled = summed / summed_mask\n",
        "        shared = self.shared_projection(pooled)\n",
        "        emo_logits = self.emotion_head(shared)\n",
        "        hid_logits = self.hidden_head(shared).squeeze(-1)\n",
        "        return emo_logits, hid_logits\n",
        "\n",
        "num_emotions = len(class_names)\n",
        "model = EnhancedEmotionHiddenModel(model_name, num_emotions, dropout_p=0.3).to(device)\n",
        "\n",
        "state_dict = torch.load(f\"{drive_path}/model_state.pt\", map_location=device)\n",
        "model.load_state_dict(state_dict)\n",
        "model.eval()\n",
        "\n",
        "print(f\"Model loaded successfully from '{drive_path}'\")\n",
        "print(f\"Classes: {class_names}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "e:\\Sliit\\Y4\\Research\\Rivin\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "e:\\Sliit\\Y4\\Research\\Rivin\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Asus\\.cache\\huggingface\\hub\\models--microsoft--deberta-v3-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n",
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "e:\\Sliit\\Y4\\Research\\Rivin\\.venv\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:566: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/model/label_encoder.pkl'",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# tokenizer + labels\u001b[39;00m\n\u001b[32m     11\u001b[39m tokenizer = AutoTokenizer.from_pretrained(model_name)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdrive_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/label_encoder.pkl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     13\u001b[39m     le = pickle.load(f)\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdrive_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/class_names.json\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
            "\u001b[36mFile \u001b[39m\u001b[32me:\\Sliit\\Y4\\Research\\Rivin\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:344\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    337\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    338\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    339\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    341\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    342\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m344\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/model/label_encoder.pkl'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynfF-dwkjvWj"
      },
      "source": [
        "emotion_id2label = {i: lab for i, lab in enumerate(class_names)}\n",
        "\n",
        "def predict_emotion(text, emoji_char=\"\"):\n",
        "    model.eval()\n",
        "    proc_text = build_input(text, emoji_char)\n",
        "    enc = tokenizer(\n",
        "        proc_text,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=128,\n",
        "        return_tensors=\"pt\",\n",
        "    ).to(device)\n",
        "    with torch.no_grad():\n",
        "        emo_logits, hid_logits = model(\n",
        "            input_ids=enc[\"input_ids\"],\n",
        "            attention_mask=enc[\"attention_mask\"],\n",
        "        )\n",
        "        emo_probs = torch.softmax(emo_logits, dim=-1)[0]\n",
        "        hid_prob = torch.sigmoid(hid_logits)[0].item()\n",
        "\n",
        "    emo_id = int(torch.argmax(emo_probs).item())\n",
        "    return {\n",
        "        \"emotion\": emotion_id2label[emo_id],\n",
        "        \"emotion_conf\": float(emo_probs[emo_id].item()),\n",
        "        \"hidden_flag\": bool(hid_prob > 0.5),\n",
        "        \"hidden_prob\": hid_prob,\n",
        "    }\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34JFLQy4jmxF",
        "outputId": "016a7e72-5817-4270-ea86-813e410825eb"
      },
      "source": [
        "test_examples = [\n",
        "    (\"I’m not angry 😡, just frustrated\", \"😡\"),\n",
        "    (\"Not angry 😡, just annoyed\", \"😡\"),\n",
        "    (\"I am angry 😡\", \"😡\"),\n",
        "(\"This makes me angry 😠\", \"😠\"),\n",
        "(\"I’m really mad about this 😡\", \"😡\"),\n",
        "(\"I’m upset and angry 😠\", \"😠\"),\n",
        "    (\"I understand your decision, happy to move forward\", \"🙂😡\"),\n",
        "        (\"I dont love you ☹️😒\", \"☹️😒\")\n",
        "\n",
        "\n",
        "\n",
        "]\n",
        "\n",
        "\n",
        "for text, emo in test_examples:\n",
        "    out = predict_emotion(text, emoji_char=emo)\n",
        "    print(\"text:\", text)\n",
        "    print(\"emoji:\", emo)\n",
        "    print(\"pred:\", out)\n",
        "    print(\"----\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "text: I’m not angry 😡, just frustrated\n",
            "emoji: 😡\n",
            "pred: {'emotion': 'anger', 'emotion_conf': 0.4897781014442444, 'hidden_flag': False, 'hidden_prob': 0.08016029745340347}\n",
            "----\n",
            "text: Not angry 😡, just annoyed\n",
            "emoji: 😡\n",
            "pred: {'emotion': 'anger', 'emotion_conf': 0.4608343243598938, 'hidden_flag': False, 'hidden_prob': 0.05819237604737282}\n",
            "----\n",
            "text: I am angry 😡\n",
            "emoji: 😡\n",
            "pred: {'emotion': 'anger', 'emotion_conf': 0.3995002806186676, 'hidden_flag': False, 'hidden_prob': 0.05505933612585068}\n",
            "----\n",
            "text: This makes me angry 😠\n",
            "emoji: 😠\n",
            "pred: {'emotion': 'joy', 'emotion_conf': 0.46605268120765686, 'hidden_flag': False, 'hidden_prob': 0.08976083993911743}\n",
            "----\n",
            "text: I’m really mad about this 😡\n",
            "emoji: 😡\n",
            "pred: {'emotion': 'anger', 'emotion_conf': 0.43273335695266724, 'hidden_flag': False, 'hidden_prob': 0.07402713596820831}\n",
            "----\n",
            "text: I’m upset and angry 😠\n",
            "emoji: 😠\n",
            "pred: {'emotion': 'anger', 'emotion_conf': 0.35993197560310364, 'hidden_flag': False, 'hidden_prob': 0.06076928600668907}\n",
            "----\n",
            "text: I understand your decision, happy to move forward\n",
            "emoji: 🙂😡\n",
            "pred: {'emotion': 'sadness', 'emotion_conf': 0.37406426668167114, 'hidden_flag': True, 'hidden_prob': 0.7869176268577576}\n",
            "----\n",
            "text: I dont love you ☹️😒\n",
            "emoji: ☹️😒\n",
            "pred: {'emotion': 'sadness', 'emotion_conf': 0.6684856414794922, 'hidden_flag': False, 'hidden_prob': 0.43668803572654724}\n",
            "----\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Rivin (3.12.12)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "04bfe60e231b46a4bed4dffc950d7d3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c39c35203ce4c379875615b50188d1c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15947573fc1b4102acfb0c2726dbe173": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb1bff475dd34183851379e3702c858a",
            "placeholder": "​",
            "style": "IPY_MODEL_290e9be44ac74d96a63b4f03582a2f77",
            "value": " 2.46M/2.46M [00:01&lt;00:00, 1.79MB/s]"
          }
        },
        "20154019142340fa808961e59c3efdbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fea955f11f554bc1b9f519ec2f49fb45",
              "IPY_MODEL_d7b76130b4944799b8a0ee0616ae1524",
              "IPY_MODEL_2ec114f6182947a1ac10c5adcd5e96e8"
            ],
            "layout": "IPY_MODEL_b7a0e1d8e9dd4197b3b30cbbba90bd7b"
          }
        },
        "20c05a5c278a4eb5851ce334208cbee3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21b0ea8ed95b47b69a28db2c42d70c17": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "290e9be44ac74d96a63b4f03582a2f77": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c632ba3df3d46758b864d9603b8ab02": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ec114f6182947a1ac10c5adcd5e96e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_548ccbebd36b413aae2ccb8f0d36887c",
            "placeholder": "​",
            "style": "IPY_MODEL_04bfe60e231b46a4bed4dffc950d7d3e",
            "value": " 371M/371M [00:04&lt;00:00, 69.6MB/s]"
          }
        },
        "302dfdd733804e44935d01226552d7be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3b63c02e35d147919e22b9e88c37181b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44403e71a4534f4cbab9396542eecf0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c632ba3df3d46758b864d9603b8ab02",
            "placeholder": "​",
            "style": "IPY_MODEL_62deda4525db4abd848c64ac27799dee",
            "value": " 579/579 [00:00&lt;00:00, 14.0kB/s]"
          }
        },
        "4890a92d817a4c0e9fe4bf5f4018c017": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7498bddc963d4b8b9db31e2de2d02c22",
              "IPY_MODEL_726f00fd15b546e491ca74cbbdb3be37",
              "IPY_MODEL_44403e71a4534f4cbab9396542eecf0a"
            ],
            "layout": "IPY_MODEL_edf7791fbd5e472da26d7cab35ae9d40"
          }
        },
        "51e7ce55578746bca4afcd97f88dc321": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70233b8c61764147bbeb4dbb2b40aa47",
            "placeholder": "​",
            "style": "IPY_MODEL_5b28680865534b20b382ce42f4219af9",
            "value": " 371M/371M [00:02&lt;00:00, 282MB/s]"
          }
        },
        "548ccbebd36b413aae2ccb8f0d36887c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b28680865534b20b382ce42f4219af9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "624eea62bc304262a8e5b0f470e5f0ac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62deda4525db4abd848c64ac27799dee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6434bd9e7a0a4ed6ad0bf6fd9d2a15ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "65f44fa0d83e487d9ae3d88523495861": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6913fd51477e456c97653d19ebf3d1a2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70233b8c61764147bbeb4dbb2b40aa47": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "726f00fd15b546e491ca74cbbdb3be37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7aa909d359d84dd0a82dfeb7e4cadf15",
            "max": 579,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_df23d10249764f04a67fe098c1ac7498",
            "value": 579
          }
        },
        "7498bddc963d4b8b9db31e2de2d02c22": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a24eb8385daa4e2f9a225e3cbc6535b3",
            "placeholder": "​",
            "style": "IPY_MODEL_83a326aa0310428eb1871e1520381664",
            "value": "config.json: 100%"
          }
        },
        "7aa909d359d84dd0a82dfeb7e4cadf15": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83a326aa0310428eb1871e1520381664": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "884da155e714426e835a372314d58eff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6913fd51477e456c97653d19ebf3d1a2",
            "placeholder": "​",
            "style": "IPY_MODEL_935e7d74ed6040fe980b18171b85b3f7",
            "value": "model.safetensors: 100%"
          }
        },
        "8a2c0c7e821f4bb9a64cbdc0c12157f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8c8332ecf2249fe818a18acb23a55f1",
            "placeholder": "​",
            "style": "IPY_MODEL_f19658c4a19444e2b4e3978ea2c778b1",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "8b6965f22f174a79aa27b87a6991dc77": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8dffd51e8a81414080523ec642bb165c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92013bba4f0f4c5fb691abb492605567": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ac52380ebabb4e37b2d0c7aea66610c4",
              "IPY_MODEL_a39e6e7b5ba84adab5d11a85a02116c3",
              "IPY_MODEL_15947573fc1b4102acfb0c2726dbe173"
            ],
            "layout": "IPY_MODEL_d3fb75c744e846be8d7cf4105b1ffe3c"
          }
        },
        "935e7d74ed6040fe980b18171b85b3f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94663506177040609a08c874cae771c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_884da155e714426e835a372314d58eff",
              "IPY_MODEL_f4d19f582752419c8b1298ab76ffe93a",
              "IPY_MODEL_51e7ce55578746bca4afcd97f88dc321"
            ],
            "layout": "IPY_MODEL_21b0ea8ed95b47b69a28db2c42d70c17"
          }
        },
        "a24eb8385daa4e2f9a225e3cbc6535b3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a39e6e7b5ba84adab5d11a85a02116c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20c05a5c278a4eb5851ce334208cbee3",
            "max": 2464616,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d06124359b1e42289721912eb73a5a0a",
            "value": 2464616
          }
        },
        "a3be57c4cfa0418a93ed59770dd24ab5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f71d2cfbe42143bc85af0d7777127e77",
            "placeholder": "​",
            "style": "IPY_MODEL_f84b99470a7249fc9017d5b658d1efac",
            "value": " 52.0/52.0 [00:00&lt;00:00, 2.36kB/s]"
          }
        },
        "ac52380ebabb4e37b2d0c7aea66610c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6b05fcfb9e04163a8ea8ad4d49f89e7",
            "placeholder": "​",
            "style": "IPY_MODEL_8dffd51e8a81414080523ec642bb165c",
            "value": "spm.model: 100%"
          }
        },
        "aec0713e4f134811b948662d8393cba0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65f44fa0d83e487d9ae3d88523495861",
            "max": 52,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_302dfdd733804e44935d01226552d7be",
            "value": 52
          }
        },
        "b7a0e1d8e9dd4197b3b30cbbba90bd7b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6b05fcfb9e04163a8ea8ad4d49f89e7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb1bff475dd34183851379e3702c858a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d06124359b1e42289721912eb73a5a0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d3fb75c744e846be8d7cf4105b1ffe3c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7b76130b4944799b8a0ee0616ae1524": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f963410e974f4cf88fb93a60dadc57f2",
            "max": 371146213,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ddb62225a6904796adefa8c6885affde",
            "value": 371146213
          }
        },
        "ddb62225a6904796adefa8c6885affde": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "df23d10249764f04a67fe098c1ac7498": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e8c8332ecf2249fe818a18acb23a55f1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edf7791fbd5e472da26d7cab35ae9d40": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f09525107b50474ab191fb3bf47b2353": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8a2c0c7e821f4bb9a64cbdc0c12157f2",
              "IPY_MODEL_aec0713e4f134811b948662d8393cba0",
              "IPY_MODEL_a3be57c4cfa0418a93ed59770dd24ab5"
            ],
            "layout": "IPY_MODEL_624eea62bc304262a8e5b0f470e5f0ac"
          }
        },
        "f19658c4a19444e2b4e3978ea2c778b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4d19f582752419c8b1298ab76ffe93a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c39c35203ce4c379875615b50188d1c",
            "max": 371101258,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6434bd9e7a0a4ed6ad0bf6fd9d2a15ce",
            "value": 371101258
          }
        },
        "f71d2cfbe42143bc85af0d7777127e77": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f84b99470a7249fc9017d5b658d1efac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f963410e974f4cf88fb93a60dadc57f2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fea955f11f554bc1b9f519ec2f49fb45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b6965f22f174a79aa27b87a6991dc77",
            "placeholder": "​",
            "style": "IPY_MODEL_3b63c02e35d147919e22b9e88c37181b",
            "value": "pytorch_model.bin: 100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}